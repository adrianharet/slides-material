%% magick convert -density 1200 test.pdf test.png
\documentclass[preview, border={0pt 5pt 0pt 1pt}, varwidth=19.5cm]{standalone} % border options are {left bottom right top}

\input{input/packages.tex}
\input{input/colors.tex}
\input{input/macros.tex}

\begin{document}
    %% Model
    % \begin{table}
    %     \begin{tabular}{rl}
    %         agents & \(1, 2, \dots , n\) \\
    %         [0.4em]
    %         time & \(t \in \{0, 1, 2, \dots \} \) \\
    %         [0.4em]
    %         true state & \(\mu \in (0, 1)\) \\
    %         [0.4em]
    %         belief of agent \(i\) at \(t\) & number between \(0\) and \(1\)\\
    %                                        & drawn from a distribution with mean \(\mu\) \\
    %                                        & and finite variance above a threshold \(\delta > 0\)\\
    %         [0.4em]
    %         social network & aperiodic, strongly connected directed graph with agents as vertices, \\ 
    %                        & and who-pays-attention-to-who as edges \\
    %         [0.4em]
    %         agent \(i\)'s neighborhood & agents that \(i\) pays attention to \\
    %         [0.4em]
    %         weight on edge from \(i\) to \(j\) & number that indicates how much weight \(i\) places on \(j\)'s opinion;\\ 
    %                                            & we assume \(i\) distributes a total weight of \(1\) across \(i\)'s neighborhood\\
    %         [0.4em]
    %         update rule & at time \(t+1\) every agent updates their belief \\ 
    %                     & to a weighted average over the beliefs of neighbors
    %     \end{tabular}
    % \end{table}

    There is a set \(N = \{1, 2, \dots, n\}\) of \emph{agents}.
    Each agent \(i\) has an \emph{opinion}, or \emph{belief}, \(x_i \in [0,1]\).
    The opinions are meant to track a \emph{true state} \(\mu \in (0, 1)\).
    \vspace{1em}

    Time goes by in discrete steps \(t \in \{0, 1, 2, \dots \}\).
    Agent \(i\)'s \emph{opinion at time} \(t\) is \(x^t_i\).
    \vspace{1em}

    Agents are connected by a \emph{social network} \(G = (N, E)\), which is a directed graph.
    An edge from \(i\) to \(j\) indicates that agent \(i\) pays attention to agent \(j\).
    Agent \(i\)'s \emph{(out-)neighborhood} \(N(i)\) is the set of agents that \(i\) pays attention to:
    \begin{flalign*}
        \qquad
        N(i) &= \{ j \in N \mid (i, j) \in E \}. &
    \end{flalign*}
    Each agent \(i\) distributes a total weight of \(1\) across the agents in \(N(i)\):
    \begin{flalign*}
        \qquad
        \sum_{j \in N(i)} w_{ij} &= 1, &
    \end{flalign*}
    where \(w_{ij} > 0\) is the \emph{weight} that agent \(i\) places on agent \(j\)'s opinion.
    \vspace{1em}

    At each new time step, agents \emph{update} their opinions to a weighted average 
    of the opinions of agents they pay attention to:
    \begin{flalign*}
        \qquad
        x^{t+1}_i &= \sum_{j \in N(i)} w_{ij} x^t_j. &
    \end{flalign*}

    % \( t = \infty\)

    % We write \(G_n\) for a network with \(n\) vertices.\\

    % A sequence \(G_1, G_2, \dots , G_n, \dots \) of (strongly connected and aperiodic) networks of increasing size 
    % is \emph{wise} if the consensus belief {approaches} the true state \(\mu\) asymptotically, as \(n\) goes to infinity.

    % A sequence \(G_1, G_2, \dots , G_n, \dots \) of (strongly connected and aperiodic) networks of increasing size 
    % is \emph{wise} if and only if the eigenvector centrality of every agent \(i\) approaches \(0\) asymptotically, 
    % as \(n\) goes to infinity.

    % The eigenvector centralities are \(\bm{c} = (\nicefrac{2}{3}, \nicefrac{1}{6}, \nicefrac{1}{6})\).\\

    % Centralities indicate the importance of the nodes for \\the limit consensus belief:
    % \begin{flalign*}
    %     \left(\frac{2}{3}, \frac{1}{6}, \frac{1}{6}\right)\cdot \left(1, 0, 0\right) &= 
    %         \frac{2}{3}\cdot 1 + \frac{1}{6}\cdot 0 + \frac{1}{6}\cdot 0 &&\\ 
    %         & = \frac{2}{3}. &&
    % \end{flalign*}

    %% Model for cascades
    % \begin{table}
    %     \begin{tabular}{rl}
    %         agents & \(N = \{1, \dots , n\}\) \\
    %         alternatives & \(A = \{a,b\}\) \\
    %         true alternative & \(\theta \in A\), we usually assume \(\theta = a\) \\
    %         voter \(i\)'s signal & \(s_i \in A\)\\
    %         probability of a correct signal \(i\)'s & \(\Pr[s_i = \theta ] = p\), with \(p > \nicefrac{1}{2}\) \\
    %         agents' prior probabilities & \(\Pr\left[ \theta = a \right] = \Pr\left[ \theta = b \right] = \nicefrac{1}{2}\)\\
    %         agent \(i\)'s verdict & \(v_i \in A\) \\
    %                             & agents speak out in sequence, and see previous verdicts
    %     \end{tabular}
    % \end{table}

    % \[
    %     \Pr\left[ A | B \right] = \frac{\Pr\left[ B | A \right] \cdot \Pr\left[ A \right] }{\Pr\left[ B \right]}
    % \]

    % \begin{flalign*}
    %     \Pr\left[ \theta = a \mid s_1 = a \right] & = \frac{ \Pr\left[ s_1 = a \mid \theta = a \right] \cdot \Pr\left[ \theta = a \right]}{\Pr\left[ s_1 = a \right]}& \\
    %     \Pr\left[ \theta = b \mid s_1 = a \right] & = \frac{ \Pr\left[ s_1 = a \mid \theta = b \right] \cdot \Pr\left[ \theta = b \right]}{\Pr\left[ s_1 = a \right]}&
    % \end{flalign*}

    % With \(p > \nicefrac{1}{2}\), we have that \(\Pr\left[ \theta = a \mid s_1 = a \right] > \Pr\left[ \theta = b \mid s_1 = a \right]\).


    % \begin{flalign*}
    %     \Pr\left[ \theta = b \mid s_3 = b, v_2 = v_1 = b \right] & > \Pr\left[ \theta = a \mid s_3 = b, v_2 = v_1 = b \right] &\\
    %     \Pr\left[ \theta = b \mid s_3 = a, v_2 = v_1 = b \right] & > \Pr\left[ \theta = a \mid s_3 = a, v_2 = v_1 = b \right] &
    % \end{flalign*}

    % \(\nicefrac{1}{2(n{-}1)}\)

    % The network grows by adding agents that listen to the central agent 1.\\

    % The eigenvector centralities are:

    % \[
    %     \bm{c} = \left(\frac{1}{2}, \frac{1}{2(n-1)}, \dots , \frac{1}{2(n-1)}\right)
    % \]

    % Agent 1 retains a constant share of (network) influence as \(n\) grows.\\

    % And thus decides the consensus belief.\\

    % No bueno.
\end{document}