%% magick convert -density 1200 test.pdf test.png
\documentclass[preview, border={0pt 5pt 3pt 1pt}, varwidth=14.5cm]{standalone} % border options are {left bottom right top}

\input{input/packages.tex}
\input{input/colors.tex}
\input{input/macros.tex}

\begin{document}
\raggedright
%% Model
% \begin{table}
%     \begin{tabular}{rl}
%         voters & \(N = \{1, \dots , n\}\) \\
%         alternatives & \(A = \{a,b\}\) \\
%         correct alternative & \(a\) \\
%         voter \(i\)'s vote & \(v_i \in A\) \\
%         profile of votes & \(\bm{v} = (v_1, \dots , v_n)\) \\
%         voter \(i\)'s competence & \(\Pr[v_i = a] = p_i\), with \(p_i \in [0,1]\) \\
%         majority vote & \(F_{\maj}(\bm{v}) = x\), such that \(v_i = x\) for a (strict) majority of voters
%     \end{tabular}
% \end{table}

% % Notation
% There is a set \(N = \{1, \dots, n\}\) of \emph{voters}. 
% There are two \emph{alternatives}, \(a\) and \(b\), one of which is \emph{correct}.
% Each voter casts a \emph{vote} for one of the alternatives. We keep track of whether each voter \(i\) is 
% correct using a \emph{random variable} \(v_i\):
% \[
%     v_i = \begin{cases}
%         1, & \text{if voter } i \text{ votes for the correct alternative,} \\
%         0, & \text{otherwise.}
%     \end{cases}
% \]
% The \emph{profile} of votes is a vector \(\bm{v} = (v_1, \dots, v_n)\) of the votes cast.
% The \emph{majority outcome}\(^*\) is the alternative with the most votes.\\

% Each voter \(i\) has a \emph{competence} \(p_i\), which is their probability of voting correctly:
% \[
%     v_i = 
%     \begin{cases}
%         1, & \text{with probability } p_i, \\
%         0, & \text{with probability } 1 - p_i.
%     \end{cases}
% \]

% \footnotesize \(^*\)We assume \(n\) is odd to avoid ties.


% May I humbly point out that the vote random variables \(v_i\) 
% are called \emph{Bernoulli variables}: \(v_i = 1\) is \emph{success},
% \(v_i = 0\) is \emph{failure}.\\

% The sum of the votes is also a random variable:
% \[
%     S_n = v_1 + \dots + v_n.
% \]
% \(S_n\) tracks the number of correct votes in a profile of \(n\) votes.\\

% Note that the majority outcome is correct exactly when 
% \({S_n > \left\lfloor \nicefrac{n}{2} \right\rfloor}\).




% \({\Pr}\Big[S_n > \lfloor \nicefrac{n}{2} \rfloor \Big]\)



%% Assumptions
% \begin{description}
%     \item[(Competence)] Agents are better than random at being correct:
%     \[
%         p_i > \frac{1}{2},~\text{for any voter}~i \in N.
%     \]
%     \item[(Equal Competence)] All agents have the same competence:
%     \[
%         p_i = p_j = p,~\text{for all voters}~i,j \in N.
%     \]
%     \item[(Independence)] Voters vote independently of each other:
%     \[
%         \Pr[v_i = x, v_j=y] = \Pr[v_i=x] \cdot \Pr[v_j=y],~\text{for all voters}~i,j \in N.
%     \]
% \end{description}
% \vspace{0.1em}


% \({\Pr}{\left[ F_\maj(\bm{v}) = 1\right]}\)



% % The Condorcet Jury Theorem
% For \(n\) voters with equal competence \(p > \nicefrac{1}{2}\) that vote independently of each other,
% then, for any odd \(n\), it holds that:
% \begin{itemize}
%     \item[(1)] \({\Pr}{\Big[ S_{n+2} > \lfloor \nicefrac{(n+2)}{2} \rfloor\Big]} > 
%         {\Pr}{\Big[ S_n > \lfloor \nicefrac{n}{2} \rfloor\Big]}\), and
%     \item[(2)] \({\Pr}{\Big[ S_n > \lfloor \nicefrac{n}{2} \rfloor \Big]} \geq p\), and
%     \item[(3)] \(\lim_{n\rightarrow\infty}{\Pr}{\Big[ S_n > \lfloor \nicefrac{n}{2} \rfloor \Big]} = 1\).
% \end{itemize}


%% CJT explanations:
% \begin{itemize}
%     \item[(1)] Larger groups are more accurate than smaller groups.

%     \item[(2)] Groups are more accurate than their members.

%     \item[(3)] The probability of a correct decision approaches \(1\) as the group size increases.
% \end{itemize}


% One voter
% The profile is \(\bm{v} = (v_1)\).\\

% The probability of a correct decision is:
% \begin{flalign*}
%     {\Pr}{\Big[S_1 > 0\Big]} & = {\Pr}{\Big[v_1 = 1\Big]} &\\
%                                     & = p &\\
%                                     & > \nicefrac{1}{2}.&
% \end{flalign*}
% As \(p\) grows, so does group accuracy.


%% Two voters
% The profile is \(\bm{v} = (v_1, v_2) \).\\

% Oh wait, we're not looking at this case.


% Three voters
% The profile is \(\bm{v} = (v_1, v_2, v_3)\).\\

% The probability of a correct decision is:
% \begin{flalign*}
%     {\Pr}{\Big[S_3 > 1\Big]} 
%         & = {\Pr}{\Big[S_3 = 2 \text{ or } S_3 = 3\Big]} &\\
%         & = {\Pr}{\Big[\bm{v} \text{ is one of } (1,1,0), (1,0,1), (0,1,1) \text{ or } (1,1,1)\Big]} &\\
%         & = {\Pr}{\Big[\bm{v} = (1, 1, 0)\Big]} + 
%             {\Pr}{\Big[\bm{v} = (1, 0, 1)\Big]} +
%             {\Pr}{\Big[\bm{v} = (0, 1, 1)\Big]} +
%             {\Pr}{\Big[\bm{v} = (1, 1, 1)\Big]}
%             &\\
%         & = {\Pr}{\big[v_1 = 1\big]} \cdot {\Pr}{\big[v_2 = 1\big]} \cdot {\Pr}{\big[v_3 = 0\big]} + \\
%         & \qquad {\Pr}{\big[v_1 = 1\big]} \cdot {\Pr}{\big[v_2 = 0\big]} \cdot {\Pr}{\big[v_3 = 1\big]} + \\
%         & \qquad\quad {\Pr}{\big[v_1 = 0\big]} \cdot {\Pr}{\big[v_2 = 1\big]} \cdot {\Pr}{\big[v_3 = 1\big]} + \\
%         & \qquad\qquad {\Pr}{\big[v_1 = 1\big]} \cdot {\Pr}{\big[v_2 = 1\big]} \cdot {\Pr}{\big[v_3 = 1\big]} &\\
%         & = p \cdot p \cdot (1-p) + p \cdot(1-p) \cdot p + (1-p) \cdot p \cdot p + p \cdot p \cdot p &\\
%         & = 3p^2(1-p) + p^3 &\\
%         & > p.&
% \end{flalign*}
% Again, as \(p\) grows, so does group accuracy.\\ 

% And a group of three voters is more accurate than a single voter!


% % Five voters
% The profile is \(\bm{v} = (v_1, v_2, v_3, v_4, v_5)\).\\

% The probability of a correct decision is:
% \begin{flalign*}
%     {\Pr}{\Big[S_5 > 2 \Big]} 
%         & = {\Pr}{\Big[S_5 = 3 \text{ or } S_5 = 4 \text{ or } S_5 = 5 \Big]} &\\
%                     & = {\Pr}{\big[\bm{v} \text{ is either } (1,1,1,0,0), \dots, (1,1,1,1,0), \dots, \text{ or } (1,1,1,1,1)\big]} &\\
%                     & \dots &\\
%                     & = 10 \cdot p^3(1-p)^2 + 5 \cdot p^4(1-p) + p^5 &\\
%                     & = {5 \choose 3} p^3(1-p)^2 + {5 \choose 4} p^4(1-p) + {5 \choose 5} p^5 &
% \end{flalign*}
% Again, as \(p\) grows, so does group accuracy.\\ 

% And a group of five voters is more accurate than a group of three!



% % Any odd number of voters
% The profile is \(\bm{v} = (v_1, \dots, v_n)\), for \(n=2k+1\) and \(k \geq 1\).\\

% The probability of a correct decision is:
% \begin{flalign*}
%     {\Pr}{\Big[S_n > k \Big]} 
%         & = {\Pr}{\Big[S_n = k{+}1 \text{ or } \dots \text{ or } S_n = n\Big]} &\\
%         & = {n \choose k+1} \cdot p^{k+1}(1-p)^{n-(k+1)} + \dots + {n \choose n-1} \cdot p^{n-1}(1-p)^1 + {n \choose n} p^n & \\ 
%         & = \sum_{i=k+1}^{n} {n \choose i} \cdot p^i(1-p)^{n-i}.
% \end{flalign*}
% And it looks like the same reasoning applies: as \(n\) grows, so does group accuracy!\\

% But only as long as \(p > \nicefrac{1}{2}\)\dots




% To prove that accuracy increases with group size, we derive a recurrence relation for the probability of a correct decision
% with \(n+2\) voters, given the probability of a correct decision with \(n\) voters.\\

% Take \(n=5\).

% \[
%     {\Pr}{\Big[ S_5 > 2 \Big]} = 
%         (1-p)^2 \cdot {\Pr}{\Big[ S_3 > 2 \Big]} +
%         2p(1-p)^2 \cdot {\Pr}{\Big[ S_3 > 1 \Big]} +
%         p^2 \cdot {\Pr}{\Big[ S_3 > 0 \Big]}.
% \]


% \[
%     \textcolor{GameTheory}{{\Pr}{\left[ S_{n+2} > \left\lfloor\frac{n+2}{2} \right\rfloor \right]}} = 
%     (1-p)^2 \cdot \textcolor{Azure}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2}\right\rfloor + 1 \right]}} + 
%     2p(1-p)^2 \cdot \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor \right]}} + 
%     p^2 \cdot \textcolor{PastelGreen}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2} \right\rfloor - 1 \right]}}        
% \]

% \[
%     \textcolor{GameTheory}{{\Pr}{\Big[ S_{2k+3} > k{+}1 \Big]}} = 
%     (1-p)^2 \cdot \textcolor{Azure}{{\Pr}{\Big[ S_{2k+1} > k {+} 1 \Big]}} + 
%     2p(1-p)^2 \cdot \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} + 
%     p^2 \cdot \textcolor{PastelGreen}{{\Pr}{\Big[ S_{2k+1} > k {-} 1 \Big]}}.
% \]


% \begin{align*}
%     \textcolor{PastelGreen}{{\Pr}{\Big[ S_{2k+1} > k{-}1 \Big]}} 
%         & = \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} + {\Pr}{\Big[ S_{2k+1} = k \Big]} &\\
%         & = \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} + \binom{2k{+}1}{k}\cdot p^k(1-p)^{k+1} &\\
%     \textcolor{Azure}{{\Pr}{\Big[ S_{2k+1} > k{+}1 \Big]}} 
%         & = \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} - {\Pr}{\Big[ S_{2k+1} = k{+}1 \Big]} &\\
%         &= \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} - \binom{2k+1}{k+1}\cdot p^{k+1}(1-p)^{k}
% \end{align*}

% \[
%     {2k+1 \choose k} = {2k+1 \choose k+1} = c
% \]

% \begin{align*}
%     \textcolor{GameTheory}{{\Pr}{\Big[ S_{2k+3} > k{+}1 \Big]}} 
%     & = (1-p)^2 \cdot \textcolor{Azure}{{\Pr}{\Big[ S_{2k+1} > k {+} 1 \Big]}} + 
%         2p(1-p)^2 \cdot \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} + 
%         p^2 \cdot \textcolor{PastelGreen}{{\Pr}{\Big[ S_{2k+1} > k {-} 1 \Big]}} \\
%     & \dots \\
%     & = \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}} + c \cdot p^{k+1} \cdot (1-p)^{k+1} \cdot (2p-1)\\ 
%     & > \textcolor{Honey}{{\Pr}{\Big[ S_{2k+1} > k \Big]}}.
% \end{align*}



% \begin{align*}
%     \textcolor{PastelGreen}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor-1 \right]}} &= 
%     \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2} \right\rfloor \right]}} + 
%     \binom{n}{\lfloor\nicefrac{n}{2}\rfloor}\cdot p^{\lfloor\nicefrac{n}{2}\rfloor}(1-p)^{\lfloor\nicefrac{n}{2}\rfloor+1}\\
%     \textcolor{Azure}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor+1 \right]}} &= 
%     \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2} \right\rfloor \right]}} -
%     \binom{n}{\lfloor\nicefrac{n}{2}+1\rfloor}\cdot p^{\lfloor\nicefrac{n}{2}\rfloor+1}(1-p)^{\lfloor\nicefrac{n}{2}\rfloor}
% \end{align*}


% Generalizing the previous identity we get the following recurrence:
% {
%     \footnotesize
%     \[
%         \textcolor{GameTheory}{{\Pr}{\left[ S_{n+2} > \left\lfloor\frac{n+2}{2} \right\rfloor \right]}} = 
%         (1-p)^2 \cdot \textcolor{Azure}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2}\right\rfloor + 1 \right]}} + 
%         2p(1-p)^2 \cdot \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor \right]}} + 
%         p^2 \cdot \textcolor{PastelGreen}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2} \right\rfloor - 1 \right]}}        
%     \]
% }

% \noindent
% The events on the right-hand-side can be rewritten as:
% {
% \footnotesize
% \begin{align*}
%     \textcolor{PastelGreen}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor-1 \right]}} &= 
%     \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2} \right\rfloor \right]}} + 
%     \binom{n}{\lfloor\nicefrac{n}{2}\rfloor}\cdot p^{\lfloor\nicefrac{n}{2}\rfloor}(1-p)^{\lfloor\nicefrac{n}{2}\rfloor+1}\\
%     \textcolor{Azure}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor+1 \right]}} &= 
%     \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor\frac{n}{2} \right\rfloor \right]}} -
%     \binom{n}{\lfloor\nicefrac{n}{2}+1\rfloor}\cdot p^{\lfloor\nicefrac{n}{2}\rfloor+1}(1-p)^{\lfloor\nicefrac{n}{2}\rfloor}
% \end{align*}
% }

% \noindent
% Plug second and third identities into first, and write \(\binom{n}{\lfloor\nicefrac{n}{2}\rfloor} = \binom{n}{\lfloor\nicefrac{n}{2}\rfloor+1}=c\):
% {
%     \footnotesize
%     \[
%         \textcolor{GameTheory}{{\Pr}{\left[ S_{n+2} > \left\lfloor\frac{n+2}{2} \right\rfloor \right]}} = 
%         \textcolor{Honey}{{\Pr}{\left[ S_n > \left\lfloor \frac{n}{2}\right\rfloor \right]}} + 
%         c \cdot p^{\lfloor\nicefrac{n}{2}\rfloor+1}(1-p)^{\lfloor\nicefrac{n}{2}\rfloor+1}(2p-1).
%     \]
% }

% \noindent
% Since \(\nicefrac{1}{2}<p<1\), the second term on the right-hand side is positive.

% This follows from Claim 1:
% \begin{flalign*}
%     p & = {\Pr}{\Big[ S_1 > 0 \Big]} \\ 
%       & < {\Pr}{\Big[ S_3 > 1 \Big]} \\
%       & \dots \\ 
%       & < \Pr{\Big[ S_n > \lfloor \nicefrac{n}{2} \rfloor \Big]} \\ 
%       & \dots 
% \end{flalign*}

%% Weak Law of Large Numbers
% If \(X_1\), \dots, \(X_n\) are independent and identically distributed (i.i.d.) random variables
% such that \(\EXP[X_i] = \mu\), then, for any \(\epsilon > 0\), it holds that:
% \[
%     \lim_{n \rightarrow \infty} \Pr\left[ \left|\frac{X_1 + \dots + X_n}{n} - \mu\right|< \epsilon \right] = 1.
% \]

% In our case, each independent random variable \(v_i\) 
% keeps track of whether voter \(i\) votes correctly, with:
% \[
%     v_i = \begin{cases}
%         1, & \text{with probability } p \\
%         0, & \text{with probability } 1-p.
%     \end{cases}
% \]
% The majority vote is correct when:
% \[
%     v_1 + v_2 + \dots + v_n > \frac{n}{2} \quad\text{iff}\quad
%     \frac{v_1 + \dots v_n}{n} > \frac{1}{2}.
% \]


% The \emph{Law of Large Numbers} gives us that, as \(n\) grows, \(\nicefrac{(v_1 + \dots v_n)}{n}\)
% gets very close to the expected value of the random variables \(v_i\).\\

% The expected value (i.e., mean \(\mu\)) is:
% \begin{flalign*}
%     && \EXP\big[v_i\big] & = 1 \cdot p + 0 \cdot (1-p) &\\ 
%     &&           & = p.&
% \end{flalign*}
% So, for very large \(n\), with high probability:
% \begin{flalign*}
%     && \frac{v_1 + \dots + v_n}{n} & \approx p &\\ 
%     &&                             & > \frac{1}{2}.
% \end{flalign*}
% This can be made precise with an appropriate choice of \(\epsilon\) 
% in the \emph{Law of Large Numbers}.






% Take three voters with competences \(p_1\), \(p_2\), \(p_3\).\\ 

% The probability of a correct majority decision is:
% \begin{flalign*}
%     \quad{\Pr}\Big[ S_n > 1 \Big] & = {\Pr}{\Big[S_n = 2 \text{ or } S_n = 3 \Big]} &\\
%                                   & = p_1p_2(1-p_3) + p_1(1-p_2)p_3 + (1-p_1)p_2p_3 + p_1p_2p_3 &\\
%                                   & = p_1p_2 + p_2p_3 + p_1p_3 - 2p_1p_2p_3.&
% \end{flalign*}
% For \(n\) voters, \(n\) odd, with competences \(p_1\), \dots, \(p_n\), the probability of a correct majority decision is:
% \begin{flalign*}
%     \quad{\Pr}\Big[ S_n > \nicefrac{n}{2} \Big] & = 
%         \sum_{C \subseteq N, |C| > \nicefrac{n}{2}} \left(\prod_{i \in C} p_i \cdot \prod_{N \setminus C}(1-p_i) \right).&  
% \end{flalign*}





% Take three voters with competences \(p_1 = 1\), \(p_2 = \nicefrac{3}{4}\) and \(p_3 = \nicefrac{5}{8}\).\\

% The probability of a correct majority decision is:
% \begin{flalign*}
%     \quad{\Pr}\Big[ S_3 > 1 \Big] & = {\Pr}{\Big[S_3 = 2 \text{ or } S_3 = 3 \Big]} &\\
%                                   & = p_1p_2(1-p_3) + p_1(1-p_2)p_3 + (1-p_1)p_2p_3 + p_1p_2p_3 &\\
%                                   & = 1 \cdot \frac{3}{4} \cdot \left(1-\frac{5}{8}\right) + 1 \cdot \left(1-\frac{3}{4}\right) \cdot \frac{5}{8} + (1-1) \cdot \frac{3}{4} \cdot \frac{5}{8} + 1 \cdot \frac{3}{4} \cdot \frac{5}{8} &\\
%                                   & = 0.90625& \\
%                                   & < p_1.&
% \end{flalign*}
% Now we have an expert (i.e., voter \(1\)) who is actually better than the majority vote.





% Suppose we add two voters with competences \(p_4 = \nicefrac{9}{16}\) and \(p_5 = \nicefrac{17}{32}\)
% to the previous group.\\

% We now have a group of five voters whose competences are
% \({\bm{p} = \Big(1, \nicefrac{3}{4}, \nicefrac{5}{8}, \nicefrac{15}{16}, \nicefrac{16}{32} \Big)}\).\\

% The probability of a correct majority decision is:
% \begin{flalign*}
%     \quad{\Pr}\Big[ S_5 > 2 \Big] & \approx 0.84\\ 
%                                   & < 0.91 & \\
%                                   & \approx {\Pr}\Big[ S_3 > 1 \Big].&
% \end{flalign*}
% Adding voters \(4\) and \(5\) made the group less accurate than before!



% Take \(n\) voters with competences:
% \begin{flalign*}
%   \quad p_1 &= \frac{1}{2} + \frac{1}{2}, \quad p_2 = \frac{1}{2} + \frac{1}{2^2}, \quad \dots, \quad p_n = \frac{1}{2} + \frac{1}{2^n}.&      
% \end{flalign*}

% The probability of a correct majority decision, as \(n\) grows, is:
% \begin{flalign*}
%   \quad\lim_{n \rightarrow \infty} {\Pr}\Big[ S_n > \nicefrac{n}{2} \Big] &= \frac{1}{2}.&
% \end{flalign*}
% Even though the competence of each voter is above \(\nicefrac{1}{2}\), 
% the probability of a correct majority decision does not go asymptotically towards \(1\).





% For an odd number \(n\) of voters with competences \(p_1\), \dots , \(p_n\) 
% who vote independently of each other, then, if \(p_i > \nicefrac{1}{2} + \epsilon \), 
% for every voter \(i\) and some \(\epsilon > 0\), it holds that:
% \[
%   \lim_{n\rightarrow\infty}{\Pr}\Big[ S_n > \nicefrac{n}{2} \Big] = 1.
% \]    


%% Proof
% Take \(\bm{p} = \Big(p_1, \dots, p_n\Big)\) to be the vector of competences of \(n\) voters.
% \vskip 1em

% Note, first, that if we improve the competence of one voter, 
% then the probability of a correct majority decision increases.
% \vskip 1em

% Formally, suppose we replace some \(p_i\) in \(\bm{p}\) with \(p'_i > p_i\), 
% while keeping all other competences the same.
% We say the resulting vector \(\bm{p}'\) is an \emph{improvement} of \(\bm{p}\).    
% If \(S'_n\) is the sum of the votes determined by \(\bm{p}'\), we have that: 
% \[
%   {\Pr}\Big[ S'_n > \nicefrac{n}{2}\Big] > {\Pr}\Big[ S_n > \nicefrac{n}{2}\Big]
% \]

% Note, now, that we can get from 
% \(\bm{p}^* = \Big(\nicefrac{1}{2} + \epsilon, \dots, \nicefrac{1}{2} + \epsilon \Big)\)
% to any \(\bm{p} = \Big(p_1, \dots, p_n\Big)\) by a series of improvements.
% \vskip 1em

% But we already know, from the Condorcet Jury Theorem, that the group competence of \(\bm{p}^*\) 
% approaches \(1\) asymptotically. So the group competence of \(\bm{p}\) does the same.




% For an odd number \(n\) of voters with accuracies normally distributed 
% with a mean of \(p > \nicefrac{1}{2}\) and a variance of \(\nicefrac{p(1-p)}{n}\), then:
% \[
%   \lim_{n\rightarrow\infty}{\Pr}\Big[ S_n > \nicefrac{n}{2} \Big] = 1.
% \]    



% Recall that votes are \(v_i \in \{0, 1\}\).
% The \emph{sum of the votes} is \(S_n = v_1 + \dots + v_n\),
% and the majority outcome is correct when \(S_n > \nicefrac{n}{2}\),
% which is equivalent to:
% \[
%     \frac{1}{n} \cdot v_1 + \dots + \frac{1}{n} \cdot v_n > \frac{1}{2}.
% \]
% We can interpret \(\nicefrac{1}{n}\) as a weight, such that each vote \(v_i\) is weighted equally.
% \vspace{1em}

% Relaxing this assumption, we assume that each voter \(i\) has a \emph{weight} \(w_i \in \mathbb{R}\).
% \vspace{1em}

% The \emph{weighted sum of the votes} is:
% \[
%     W_n = w_1 v_1 + \dots + w_n v_n,
% \]
% We define the \emph{group vote} to be \(a\) (the correct alternative) if:
% \[
%     W_n > \frac{w_1 + \dots + w_n}{2}.
% \]




% Take three voters, with weights \(w_1 = 4\), \(w_2 = 1\), \(w_3 = 1\).
% The weighted sum of the votes is:
% \begin{flalign*}
%     \qquad W_3 & = 4v_1 + v_2 + v_3, &
% \end{flalign*}
% and the threshold for voting for \(a\) is \(3\).
% \vspace{1em}

% Suppose the votes are \(v_1 = 1\), \(v_2 = 0\) and \(v_3 = 0\).
% The weighted sum is:
% \begin{flalign*}
%     \qquad W_3 & = 4 > 3,&
% \end{flalign*}
% which means the group vote is \(a\). The group votes correctly, 
% despite a wrong vote from \(v_2\) and \(v_3\).
% \vspace{1em}

% If the votes are \(v_1 = 0\), \(v_2 = 1\) and \(v_3 = 1\), the weighted sum is:
% \begin{flalign*}
%     \qquad W_3 & = 2 < 3,&
% \end{flalign*}
% which means the group vote is \(b\). The group votes incorrectly, despite 
% correct votes from \(v_2\) and \(v_3\).





% Take three voters, with weights \(w_1 = 2\), \(w_2 = -3\), \(w_3 = -3\).
% The weighted sum of the votes is:
% \begin{flalign*}
%     \qquad W_3 & = 2v_1 - 3v_2 - 3v_3, &
% \end{flalign*}
% and the threshold for voting for \(a\) is \(-2\).
% \vspace{1em}

% Suppose the votes are \(v_1 = 1\), \(v_2 = 1\) and \(v_3 = 1\).
% The weighted sum is:
% \begin{flalign*}
%     \qquad W_3 & = -4 < -2,&
% \end{flalign*}
% which means the group vote is \(b\).

% \vspace{1em}

% The group votes incorrectly, 
% even though everyone votes correctly (!!!).
% \vspace{1em}

% Wut?



% \({\Pr}\bigg[ W_n > \frac{w_1 + \dots + w_n}{2} \bigg]\)




For \(n\) voters with competences \(p_1\), \dots, \(p_n\), 
the neutral\(^*\) decision rule that maximizes the probability of a correct decision is
a weighted voting rule with weights \(w_1\), \dots, \(w_n\) such that:
\[
    w_i \propto \ln{\frac{p_i}{1-p_i}}, \text{ for every voter } i.
\]



%% Model for cascades
% \begin{table}
%     \begin{tabular}{rl}
%         agents & \(N = \{1, \dots , n\}\) \\
%         alternatives & \(A = \{a,b\}\) \\
%         better alternative & \(\theta \in A\), we usually assume \(\theta = a\) \\
%         voter \(i\)'s signal & \(s_i \in A\)\\
%         probability of a correct signal \(i\)'s & \(\Pr[s_i = \theta ] = p\), with \(p > \nicefrac{1}{2}\) \\
%         agent \(i\)'s opinion & \(v_i \in A\) \\
%                            & agents speak out in sequence, and see previous opinions
%     \end{tabular}
% \end{table}

% \begin{table}
%     \begin{tabular}{rccc}
%         \toprule
%               & pros & cons & net \\
%         \midrule
%         \(a\) & \(a_1, a_2, a_3, a_4\) & \(\overline{a}_1\) & 3 \\
%         \(b\) & \(b_1, b_2\) & \(\emptyset\) & 2 \\
%         \bottomrule
%     \end{tabular}
% \end{table}

% \begin{table}
%     \begin{tabular}{rccc}
%         \toprule
%               & pros & cons & net \\
%         \midrule
%         \(a\) & \(a_3, a_4\) & \(\overline{a}_1\) & 1 \\
%         \(b\) & \(b_1,b_2\) & \(\emptyset\) & 2 \\
%         \bottomrule
%     \end{tabular}
% \end{table}

% \(b_1, b_2, \overline{a}_1\)
\end{document}