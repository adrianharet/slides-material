%% magick convert -density 1200 test.pdf test.png
\documentclass[preview, varwidth=15cm, border={0pt 5pt 0pt 1pt}]{standalone} % border options are {left bottom right top}

\input{input/packages.tex}
\input{input/colors.tex}
\input{input/macros.tex}

\newcommand{\UTFT}{{\text{UTFT}}}
\newcommand{\ALLD}{{\text{ALLD}}}

\begin{document}\raggedright
    % \begin{table}
    %     \begin{tabular}{rl}
    %         players & \(N = \{1, \dots , n\}\) \\
    %         strategy of player \(i\) & \(s_i\) \\
    %         profile of strategies & \(\bm{s} = (s_1, \dots , s_n) \) \\
    %         utility of player \(i\) with strategy profile \(\bm{s} \) & \(u_i(\bm{s}) \in \mathbb{R}\) \\
    %         strategy profile \(\bm{s} \) without \(s_i\) & \(\bm{s}_{-i} = (s_1, \dots , s_{i-1}, s_{i+1}, \dots , s_n)\) \\
    %         \(\bm{s} \), alternatively & \(\bm{s} = (s_i, \bm{s}_{-i} ) \)
    %     \end{tabular}
    % \end{table}

    % \(u_1(\text{Keep}, \text{Keep}) = 1\), \(u_2(\text{Invest}, \text{Keep}) = 4\), \dots 
    % Player \(i\)'s \emph{best response} to the other players' strategies 
    % \(\bm{s}_{-i} = (s_1, \dots, s_{i-1}, s_{i+1}, \dots, s_n)\)
    % is a strategy \(s^{*}_i\) such that \(u_i(s^{*}_i, \bm{s}_{-i}) \geq u_i(s_i, \bm{s}_{-i})\), 
    % for any strategy \(s_i\) of player \(i\).
    
    % A strategy profile \(\bm{s}^{*} = (s_1^{*}, \dots, s_n^{*})\) is a 
    % \emph{pure Nash equilibrium} if \(s_i^{*}\) is a best response to \(\bm{s}^*_{-i}\),
    % for every player \(i\).\\

    % In other words, \(\bm{s}^*\) is a pure Nash equilibrium if there is no player \(i\) and strategy \(s'_i\)
    % such that \(u_i(s'_i, \bm{s}^*_{-i}) > u_i(s^*_i, \bm{s}^*_{-i})\).
    % 
    % A strategy profile \(\bm{s}\) \emph{Pareto dominates} strategy profile \(\bm{s}'\) if:
    % \begin{itemize}
    %     \item[(i)] \(u_i(\bm{s}) \geq u_i(\bm{s}')\), for every agent \(i\), and 
    %     \item[(ii)] there exists an agent \(j\) such that \(u_j(\bm{s}) > u_j(\bm{s}')\). 
    % \end{itemize}
    % 
    % A strategy profile \(\bm{s}\) is \emph{Pareto optimal} if 
    % there is no (other) strategy profile \(\bm{s}'\) that Pareto dominates \(\bm{s}\).

    % \(u_1{\big(\text{1-1}, (\text{yes}, \text{no}, \text{yes})\big)} = 0\)
    % \(2+ 2 \delta + 2\delta^2 + \dots\)
    % \begin{align*}
    %     2+2\delta+ 2\delta^2 + \dots & = 2(1+\delta + \delta^2 + \dots)\\ 
    %                               & = 2\cdot \frac{1}{1-\delta}
    % \end{align*}

    % \(2\cdot (\nicefrac{1}{1-\delta})\)

    % My sweet Mil I love you very much.
    
    % \(2, 2\delta, \dots, 2\delta^{k-1}, 3\delta^k, \delta^{k+1}, \delta^{k+2}, \dots\)
    % \(2\cdot\left(\nicefrac{1}{1-\delta}\right)\)
    % \(2 + \frac{1}{1-\delta} \leq 2\cdot \frac{1}{1-\delta},\)
    % \(\delta \geq \frac{1}{2}\)
    % \begin{align*}
    %     2 + 2\delta + \dots + 2\delta^{k-1} + 3\delta^k + \delta^{k+1} + \dots &\leq 2 + 2\delta + \dots + 2\delta^{k-1} + 2\delta^k + 2\delta^{k+1} + \dots & \text{iff} \\
    %     3\delta^k + \delta^{k+1} + \dots &\leq 2\delta^k + 2\delta^{k+1} + \dots & \text{iff}\\
    %     3 + \delta + \delta^2 + ... &\leq 2 + 2\delta + 2\delta^2 + \dots & \text{iff} \\
    %     \delta & \geq \nicefrac{1}{2}. &
    % \end{align*}

    
    
    
    % A \emph{mixed strategy} \(s_i\) for player \(i\) is a probability distribution over \(i\)'s actions,
    % written \(s_i = \big(p_1, \dots , p_j, \dots \big)\), where \(p_j\) is the probability 
    % with which player \(i\) plays action \(j\).
    % \vspace{1em}

    % Note that it needs to hold that \(\sum_j p_j = 1\) and \(p_j \geq 0\).






    % If Player 1 plays \(s_1 = (0.9, 0.1)\), that means they play 
    % Heads with probability \(0.9\) and Tails with probability \(0.1\).
    % \vspace{1em}

    % Note that the pure strategies we've been dealing with so far are special cases of mixed 
    % strategies, in which one action is played with probability \(1\) 
    % and the rest with probability \(0\).



    % \(\text{state}~\ell~(p_\ell)\)
    % \(u(\text{action }k, \text{state }\ell)\)




    % Suppose Player 1 uses strategy \(s_1 = \big( 0.9, 0.1 \big)\). What should Player 2 do?
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1 \Big] & = (-1) \cdot 0.9 + 1 \cdot 0.1 &\\ 
    %                        & = -0.8.&\\
    %     \EXP\Big[\text{Tails} \mid s_1\Big] & = 1 \cdot 0.9 + (-1) \cdot 0.1 &\\ 
    %                        & = 0.8.&
    % \end{flalign*}
    % If Player 2 always plays Heads, i.e., \(s_2 = \big(1, 0 \big)\), 
    % they get an average payoff of \(-0.8\).
    % If they always play Tails, i.e., \(s'_2 = \big(0, 1 \big)\), 
    % they get an average payoff of \(0.8\).
    % \vspace{1em}

    % Would it make sense for Player 2 to mix between Heads and Tails, say with 
    % strategy \(s''_2 = \big(0.3, 0.7\big)\)? With \(s''_2\), the expected payoff of Player 2 is:
    % \begin{flalign*}
    %     \qquad\EXP\Big[s''_2 \mid s_1 \Big] & = \EXP\Big[ \text{Heads} \Big] \cdot 0.3 + \EXP\Big[ \text{Tails} \Big] \cdot 0.7 &\\ 
    %                        & = 0.32&\\
    %                        & < 0.8. &
    % \end{flalign*}    
    % Given that Player 1 plays \(s_1 = \big(0.9, 0.1\big)\), 
    % then, between \(s_2\), \(s'_2\) and \(s''_2\),
    % Player 2 would rather play \(s'_2 = \big( 0, 1 \big)\).





    % If Player 1 plays \(s_1 = \big(0.9, 0.1\big)\), 
    % Player 2's maximizes expected utility by playing \(s'_2 = \big(0, 1\big)\) (easy to check!).
    % \vspace{1em}

    % In other words, \(s'_2 = \big(0, 1\big)\) is Player 2's \emph{best response} to \(s_1 = \big(0.9, 0.1\big)\).
    % \vspace{1em}

    % So is \(\bm{s} = \big(s_1, s'_2\big)\) a Nash equilibrium?
    % \vspace{1em}

    % No! If Player 2 plays \(s'_2 = \big(0, 1\big)\), Player 1 
    % wants to deviate to \(s'_1 = \big( 0, 1\big)\):
    % \begin{flalign*}
    %     \qquad\EXP\Big[s_1 \mid s'_2 \Big] & = \EXP\Big[ \text{Heads} \mid s'_2\Big] \cdot 0.9 + \EXP\Big[ \text{Tails} \mid s'_2\Big] \cdot 0.1 &\\
    %         & = (-1) \cdot 0.9 + 1 \cdot 0.1 &\\ 
    %         & = -0.8& \\
    %     \qquad\EXP\Big[s'_1 \mid s'_2 \Big] & = \EXP\Big[ \text{Heads} \mid s'_2\Big] \cdot 0 + \EXP\Big[ \text{Tails} \mid s'_2\Big] \cdot 1 &\\
    %         & = (-1) \cdot 0 + 1 \cdot 1 &\\ 
    %         & = 1& \\
    %         & > \EXP\Big[s_1 \mid s'_2 \Big].&
    % \end{flalign*}    




    % Suppose Players 1 and 2 play mixed strategies 
    % \(s_1 = \big(p, 1-p\big)\) and \(s_2 = \big(q, 1-q\big)\), respectively, 
    % for \(p, q > 0\).
    % \vspace{1em}

    % Note that Player 2's expected payoff with these strategies is:
    % \begin{flalign*}
    %     \qquad\EXP\Big[s_2 \mid s_1\Big] & = \EXP\Big[\text{Heads} \mid s_1\Big] \cdot q + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot (1-q). &
    % \end{flalign*}
    % Suppose, now, that Player 1's strategy makes Heads more attractive for Player 2:
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1\Big] & > \EXP\Big[\text{Tails} \mid s_1\Big].&
    % \end{flalign*}
    % In this case, Player 2 would want to deviate to \(s'_2 = \big(1, 0\big)\):
    % \begin{flalign*}
    %     \qquad\EXP\Big[s'_2 \mid s_1\Big] & = \EXP\Big[\text{Heads} \mid s_1\Big] \cdot 1 + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot 0 &\\ 
    %     % & = \EXP\Big[\text{Heads} \mid s_1\Big] &\\ 
    %     & > \EXP\Big[\text{Heads} \mid s_1\Big] \cdot q + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot (1-q).&
    % \end{flalign*}

    % So \(\bm{s} = \big(s_1, s_2\big)\) cannot be a Nash equilibrium.
    % Same if \(\EXP\Big[\text{Tails} \mid s_1\Big] > \EXP\Big[\text{Heads} \mid s_1\Big]\).
    % \vspace{1em}
    
    % The only way to avoid this is for Player 1 to play a strategy \(s^*_1 = (p, 1-p)\) that makes
    % Player 2 indifferent between their actions:
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1\Big] = \EXP\Big[\text{Tails} \mid s_1\Big] & 
    %         \text{ iff } (-1) \cdot p + 1 \cdot (1-p) = 1 \cdot p + (-1) \cdot (1-p)&\\ 
    %             & \text{ iff } p = \nicefrac{1}{2}.&
    % \end{flalign*}
    % So Player 1 wants to play \(s^*_1 = \big(\nicefrac{1}{2}, \nicefrac{1}{2}\big)\). 
    % Similarly, Player 2 wants to play \(s^*_2 = \big(\nicefrac{1}{2}, \nicefrac{1}{2}\big)\). This is the mixed Nash equilibrium.




    % \(\bm{s}^* = \Big( (\nicefrac{1}{2}, \nicefrac{1}{2}), (\nicefrac{1}{2}, \nicefrac{1}{2})\Big)\)






    A two-player game is \emph{zero-sum} if players' payoffs add up to zero in every outcome.
    That is, if Player 1 plays action \(a\) and Player 2 plays action \(b\), then:
    \[
        u_1(a, b) + u_2(a, b) = 0.
    \]
    \vspace{1em}
    In other words, \(u_1(a, b) = - u_2(a, b)\).\\



    % Assume that at some time \(t\) there are \(c\) cooperators and \(d\) defectors.\\

    % The expected payoff of a cooperator is:
    % \begin{flalign*}
    % \quad\EXP\big[\text{Cooperate}\big] & = u\big(\text{Cooperate}, \text{Cooperate}\big) \cdot {\Pr}{\left[ \text{match w/ cooperator} \right]} + &\\
    %                                    &~~~~~u\big(\text{Cooperate}, \text{Defect}\big) \cdot  {\Pr}{\left[ \text{match w/ defector} \right]}&\\ 
    %                                    & = 2 \cdot \frac{c-1}{c+d} + 0 \cdot \frac{d}{c+d}.&
    % \end{flalign*}

    % The expected payoff of a defector is:
    % \begin{flalign*}
    %     \quad\EXP\big[\text{Defect}\big] & = u\big(\text{Defect}, \text{Cooperate}\big) \cdot {\Pr}{\left[ \text{match w/ cooperator} \right]} +& \\
    %                                      & ~~~~~u\big(\text{Defect}, \text{Defect}\big) \cdot {\Pr}{\left[ \text{match w/ defector} \right]}&\\ 
    %                            & = 3 \cdot \frac{c}{c+d} + 1 \cdot \frac{d-1}{c+d}.
    % \end{flalign*}
    % Note that \(\EXP[\text{Defect}] > \EXP[\text{Cooperate}]\).\\

    % Defectors grow faster than cooperators.\\ 

    % Eventually, cooperators die out.

    % Assume the proportions of Bs is \(\epsilon \), and the proportion of As is \(1-\epsilon \).\\

    % The expected payoff of A is greater than that of B if:
    % \[
    %     a(1- \epsilon ) + b \epsilon > c(1-\epsilon ) + d \epsilon,
    % \]
    % which, if we ignore the \(\epsilon \) terms, is equivalent to:
    % \[
    %     a > c.
    % \]
    % If, however, it happens that \(a=c\), then we need:
    % \[
    %     b > d.
    % \]
    % A strategy is evolutionarily stable if \(a>c\), or \(a=c\) and \(b>d\).

    % We write \(u(s_i, s_j)\) for the payoff of strategy \(s_i\) against \(s_j\).\\

    % Strategy \(s_i\) is an \emph{evolutionarily stable strategy (ESS)} if:
    % \begin{description}
    %     \item[(i)] \(u(s_i, s_i) > u(s_j, s_i)\), for all strategies \(s_j \neq s_i\), or
    %     \item[(ii)] \(u(s_i, s_i) = u(s_j, s_i)\) and \(u(s_i, s_j) > u(s_j, s_j)\), for all strategies \(s_j \neq s_i\).
    % \end{description}

    % \(b-c, b-c\)
    % \((b-c)\mu, (b-c)\mu\)
    % \(b, -c\)
    % \(-c, b\)
    % \(0, 0\)

    % TFT is an ESS if the occasional ALLD, thrown in a world where TFT is dominant,
    % does worse against a TFT than a TFT against itself.\\

    % This happens if:
    % \begin{flalign*}
    %     b < (b-c)\mu &\text{  iff  } \mu> \frac{b}{b-c} &\\
    %                  & \text{  iff  } \frac{1}{1-\delta } > \frac{b}{b-c} &\\
    %                  & \text{  iff  } \frac{1}{1-\delta } > \frac{b}{b-c} &\\
    %                  & \text{  iff  } b-c > b(1-\delta ) &\\
    %                  & \text{  iff  } \delta  > \frac{c}{b}. &
    % \end{flalign*}

    % ALLD is an ESS if a population of ALLDs cannot be invaded by TFTs.\\

    % This happens if a TFT against an ALLD does worse than an ALLD against
    % another ALLD, which is equivalent to:
    % \[
    %     -c < 0.
    % \]

    % \(\mu = \frac{1}{1-\delta}\)

    % \(b + b \cdot w + b \cdot w^2 + 0 \cdot w^3\)
    % \(-c + 0 \cdot w + 0 \cdot w^2 + 0 \cdot w^3\)
    % \((b-c) + (-c) \cdot w + 0 \cdot w^2 + 0 \cdot w^3\)
    % \((b-c) + (b-c) \cdot w + (-c) \cdot w^2 + 0 \cdot w^3\)

    % \(b \cdot (1+w+w^2)\)
    % \(-c\)
    % \(b - c \cdot (1+w)\)
    % \(b \cdot (1+w) - c \cdot (1+w+w^2)\)

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(b\) & \(-c\) & \(b-c\) &\(b-c\)\\
    %     \(t=2\) & \(b \cdot  w\) & \(0\cdot w\) & \((-c)\cdot w \) &\((b-c)\cdot w \)\\
    %     \(t=3\) & \(b \cdot w^2\) & \(0\cdot w^2 \) & \(0\cdot w^2 \) &\((-c)\cdot w^2\)\\
    %     \(t=4\) & \(0 \cdot w^3\) & \(0\cdot w^3 \) & \(0\cdot w^3 \) &\(0 \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   & \(b\cdot \epsilon_2\) 
    %             & \(-c\) 
    %             & \(b - c \cdot \epsilon_1\)
    %             & \(b \cdot \epsilon _1 - c \cdot \epsilon _2\)\\
    %     \bottomrule
    % \end{tabular}

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(b\) & \(b\) & \(b\) &\(b\)\\
    %     \(t=2\) & \(b \cdot  w\) & \(b\cdot w\) & \(b\cdot w \) &\(b\cdot w \)\\
    %     \(t=3\) & \(b \cdot w^2\) & \(b\cdot w^2 \) & \(b\cdot w^2 \) &\(b\cdot w^2\)\\
    %     \(t=4\) & \(b \cdot w^3\) & \(b\cdot w^3 \) & \(b\cdot w^3 \) &\(b \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     \\
    %     \bottomrule
    % \end{tabular}

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(0\) & \(0\) & \(0\) &\(0\)\\
    %     \(t=2\) & \(0 \cdot  w\) & \(0\cdot w\) & \(0\cdot w \) &\(0\cdot w \)\\
    %     \(t=3\) & \(0 \cdot w^2\) & \(0\cdot w^2 \) & \(0\cdot w^2 \) &\(0\cdot w^2\)\\
    %     \(t=4\) & \(0 \cdot w^3\) & \(0\cdot w^3 \) & \(0\cdot w^3 \) &\(0 \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   
    %     & \(0\)
    %     & \(0\)
    %     & \(0\)
    %     & \(0\)
    %     \\
    %     \bottomrule
    % \end{tabular}

    % Keeping in mind that, for \(0 < w < 1\), it holds that:
    % \begin{flalign*}
    %     \qquad\epsilon _n & = 1 + w + w^2 + \dots + w^n &\\
    %                 & = \frac{1-w^{n+1}}{1-w}, &
    % \end{flalign*}
    % with the infinite sum, i.e., for \(n \rightarrow \infty\), being:
    % \begin{flalign*}
    %     \qquad\overline{\epsilon} & = 1 + w + w^2 + \dots &\\
    %                 & = \lim_{n\rightarrow\infty}(1 + w + w^2 + \dots + w^n)&\\
    %                 & = \frac{1}{1-w}.&
    % \end{flalign*}



    % Note that if there is just one ALLD we get a chain of defections, 
    % and eventually all the UTFTs end up defecting permanently.\\

    % The number of rounds until a UTFT starts defecting depends on 
    % the number of consecutive UTFTs upstream:
    % \begin{itemize}
    %     \item at round \(t=2\), player \(1\) starts defecting

    %     \dots

    %     \item at round \(t = i+1\), player \(i\) starts defecting.
    % \end{itemize}
    % So the number of consecutive UTFTs upstream also determines 
    % a player's payoff.


    % An ALLD with \(u\) UTFTs upstream gets a payoff of \(b\) for \(u\) rounds 
    % (i.e., until the immediately upstream UTFT is converted to defection), 
    % and \(0\) afterwards, so its expected payoff is:
    % \begin{flalign*}
    %     \quad v(\text{ALLD}\mid u) & = b + b \cdot w + \dots + b \cdot w^{u-1} &\\
    %                          & = b \cdot(1 + w + \dots + w^{u-1}) \\ 
    %                          & = b \cdot \epsilon_{u-1}.
    % \end{flalign*}
    % A UTFT with \(u\) UTFTs upstream gets a payoff of \(b-c\) for the first \(u\) rounds 
    % (i.e., while the directly upstream player cooperates), \(-c\) at round \(u+1\)
    % (i.e., when it gets defected on), and \(0\) afterwards (after it starts defecting itself).\\

    % So, if \(u < n-1\), the expected payoff is:
    % \begin{flalign*}
    %     \quad v(\text{UTFT}\mid u) & = (b-c) + (b-c) \cdot w + \dots + (b-c) \cdot w^{u-1} + (-c) \cdot w^u &\\
    %                          & = b \cdot(1 + w + \dots + w^{u-1}) - c \cdot (1 + w + \dots + w^u)\\ 
    %                          & = b \cdot \epsilon_{u-1} - c \cdot \epsilon _u,
    % \end{flalign*}
    
    % Unless, of course, everyone is a UTFT (\(u = n-1\)), in which case payoffs are \(b-c\) forever:
    % \begin{flalign*}
    %     \quad v(\text{UTFT}\mid u) & = (b-c) + (b-c) \cdot w + (b-c) \cdot w^2 + \dots &\\
    %                          & = (b-c) \cdot(1 + w + w^2 + \dots)\\ 
    %                          & = (b-c) \cdot \overline{\epsilon },
    % \end{flalign*}
    % if \(u = n-1\).

    % Take \(p\) to be the frequency of UTFTs at round \(t\):
    % \[
    %     p = \frac{\text{\# of UTFTs at }t}{n}.
    % \]
    % The frequency of ALLDs at \(t\) is then \(1-p\).\\

    % Write \(W_\UTFT\) and \(W_\ALLD\) for the fitness of UTFT and ALLD at round \(t\).\\

    % The fitness \(W_s\) of strategy \(s\) (a function of expected payoff, computed earlier) can be interpreted 
    % as the probability that an individual using \(s\) reproduces.\\

    % So the (expected) number of UTFTs that get to reproduce at \(t\) is \(p \cdot n \cdot W_\UTFT\).\\

    % Similarly, the (expected) number of ALLDs that get reproduce at \(t\) is \((1-p) \cdot n \cdot W_\ALLD\).\\

    % Let's say that each reproducing individual has \(z\) offspring, i.e., copies of itself.\\

    % So at \(t+1\) we get \(p \cdot n \cdot W_\UTFT \cdot z\) UTFTs.\\

    % And the proportion of UTFTs at \(t+1\) is:
    % \begin{flalign*}
    %     p' & = \frac{\text{\# of UTFTs at }t+1}{\text{total \# of players at }t+1} \\
    %        & = \frac{p \cdot n \cdot W_\UTFT \cdot z}{p \cdot n \cdot W_\UTFT \cdot z + (1-p) \cdot n \cdot W_\ALLD \cdot z}\\
    %        & = \frac{p \cdot W_\UTFT}{p \cdot W_\UTFT + (1-p) \cdot W_\ALLD}.
    % \end{flalign*}

    % Assume \(\nicefrac{b}{c} = 2\).\\

    % If the initial fraction of UTFTs is above the threshold frequency,
    % the system evolves to a world with all UTFTs.\\

    % Below this threshold we get ALLDs.\\ 

    % Note that as populations grow larger, the threshold frequency becomes forbiddingly high.






    % Assume \(\nicefrac{b}{c} = 2\).\\

    % If the initial fraction of UTFTs is above the threshold frequency of \(r\),
    % UTFTs can increase when rare.\\

    % Again, for larger populations, the threshold frequency becomes forbiddingly high.
\end{document}