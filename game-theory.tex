%% magick convert -density 1200 test.pdf test.png
\documentclass[
    preview, 
    varwidth = 7.5cm, 
    border = {2pt 0pt 1pt 1pt}
    ]{standalone} % border options are {left bottom right top}

\input{input/packages.tex}
\input{input/colors.tex}
\input{input/macros.tex}

\newcommand{\UTFT}{{\text{UTFT}}}
\newcommand{\ALLD}{{\text{ALLD}}}

\begin{document}\raggedright
    % \begin{table}
    %     \begin{tabular}{rl}
    %         players & \(N = \{1, \dots , n\}\) \\
    %         strategy of player \(i\) & \(s_i\) \\
    %         profile of strategies & \(\bm{s} = (s_1, \dots , s_n) \) \\
    %         utility of player \(i\) with strategy profile \(\bm{s} \) & \(u_i(\bm{s}) \in \mathbb{R}\) \\
    %         strategy profile \(\bm{s} \) without \(s_i\) & \(\bm{s}_{-i} = (s_1, \dots , s_{i-1}, s_{i+1}, \dots , s_n)\) \\
    %         \(\bm{s} \), alternatively & \(\bm{s} = (s_i, \bm{s}_{-i} ) \)
    %     \end{tabular}
    % \end{table}

    % \(u_1(\text{Keep}, \text{Keep}) = 1\), \(u_2(\text{Invest}, \text{Keep}) = 4\), \dots 
    % Player \(i\)'s \emph{best response} to the other players' strategies 
    % \(\bm{s}_{-i} = (s_1, \dots, s_{i-1}, s_{i+1}, \dots, s_n)\)
    % is a strategy \(s^{*}_i\) such that \(u_i(s^{*}_i, \bm{s}_{-i}) \geq u_i(s_i, \bm{s}_{-i})\), 
    % for any strategy \(s_i\) of player \(i\).
    
    % A strategy profile \(\bm{s}^{*} = (s_1^{*}, \dots, s_n^{*})\) is a 
    % \emph{pure Nash equilibrium} if \(s_i^{*}\) is a best response to \(\bm{s}^*_{-i}\),
    % for every player \(i\).\\

    % In other words, \(\bm{s}^*\) is a pure Nash equilibrium if there is no player \(i\) and strategy \(s'_i\)
    % such that \(u_i(s'_i, \bm{s}^*_{-i}) > u_i(s^*_i, \bm{s}^*_{-i})\).
    % 
    % A strategy profile \(\bm{s}\) \emph{Pareto dominates} strategy profile \(\bm{s}'\) if:
    % \begin{itemize}
    %     \item[(i)] \(u_i(\bm{s}) \geq u_i(\bm{s}')\), for every agent \(i\), and 
    %     \item[(ii)] there exists an agent \(j\) such that \(u_j(\bm{s}) > u_j(\bm{s}')\). 
    % \end{itemize}
    % 
    % A strategy profile \(\bm{s}\) is \emph{Pareto optimal} if 
    % there is no (other) strategy profile \(\bm{s}'\) that Pareto dominates \(\bm{s}\).

    % \(u_1{\big(\text{1-1}, (\text{yes}, \text{no}, \text{yes})\big)} = 0\)
    % \(2+ 2 \delta + 2\delta^2 + \dots\)
    % \begin{align*}
    %     2+2\delta+ 2\delta^2 + \dots & = 2(1+\delta + \delta^2 + \dots)\\ 
    %                               & = 2\cdot \frac{1}{1-\delta}
    % \end{align*}

    % \(2\cdot (\nicefrac{1}{1-\delta})\)

    % My sweet Mil I love you very much.
    
    % \(2, 2\delta, \dots, 2\delta^{k-1}, 3\delta^k, \delta^{k+1}, \delta^{k+2}, \dots\)
    % \(2\cdot\left(\nicefrac{1}{1-\delta}\right)\)
    % \(2 + \frac{1}{1-\delta} \leq 2\cdot \frac{1}{1-\delta},\)
    % \(\delta \geq \frac{1}{2}\)
    % \begin{align*}
    %     2 + 2\delta + \dots + 2\delta^{k-1} + 3\delta^k + \delta^{k+1} + \dots &\leq 2 + 2\delta + \dots + 2\delta^{k-1} + 2\delta^k + 2\delta^{k+1} + \dots & \text{iff} \\
    %     3\delta^k + \delta^{k+1} + \dots &\leq 2\delta^k + 2\delta^{k+1} + \dots & \text{iff}\\
    %     3 + \delta + \delta^2 + ... &\leq 2 + 2\delta + 2\delta^2 + \dots & \text{iff} \\
    %     \delta & \geq \nicefrac{1}{2}. &
    % \end{align*}

    
    
    
    % A \emph{mixed strategy} \(s_i\) for player \(i\) is a probability distribution over \(i\)'s actions,
    % written \(s_i = \big(p_1, \dots , p_j, \dots \big)\), where \(p_j\) is the probability 
    % with which player \(i\) plays action \(j\).
    % \vspace{1em}

    % Note that it needs to hold that \(\sum_j p_j = 1\) and \(p_j \geq 0\).






    % If Player 1 plays \(s_1 = (0.9, 0.1)\), that means they play 
    % Heads with probability \(0.9\) and Tails with probability \(0.1\).
    % \vspace{1em}

    % Note that the pure strategies we've been dealing with so far are special cases of mixed 
    % strategies, in which one action is played with probability \(1\) 
    % and the rest with probability \(0\).



    % \(\text{state}~\ell~(p_\ell)\)
    % \(u(\text{action }k, \text{state }\ell)\)




    % Suppose Player 1 uses strategy \(s_1 = \big( 0.9, 0.1 \big)\). What should Player 2 do?
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1 \Big] & = (-1) \cdot 0.9 + 1 \cdot 0.1 &\\ 
    %                        & = -0.8.&\\
    %     \EXP\Big[\text{Tails} \mid s_1\Big] & = 1 \cdot 0.9 + (-1) \cdot 0.1 &\\ 
    %                        & = 0.8.&
    % \end{flalign*}
    % If Player 2 always plays Heads, i.e., \(s_2 = \big(1, 0 \big)\), 
    % they get an average payoff of \(-0.8\).
    % If they always play Tails, i.e., \(s'_2 = \big(0, 1 \big)\), 
    % they get an average payoff of \(0.8\).
    % \vspace{1em}

    % Would it make sense for Player 2 to mix between Heads and Tails, say with 
    % strategy \(s''_2 = \big(0.3, 0.7\big)\)? With \(s''_2\), the expected payoff of Player 2 is:
    % \begin{flalign*}
    %     \qquad\EXP\Big[s''_2 \mid s_1 \Big] & = \EXP\Big[ \text{Heads} \Big] \cdot 0.3 + \EXP\Big[ \text{Tails} \Big] \cdot 0.7 &\\ 
    %                        & = 0.32&\\
    %                        & < 0.8. &
    % \end{flalign*}    
    % Given that Player 1 plays \(s_1 = \big(0.9, 0.1\big)\), 
    % then, between \(s_2\), \(s'_2\) and \(s''_2\),
    % Player 2 would rather play \(s'_2 = \big( 0, 1 \big)\).





    % If Player 1 plays \(s_1 = \big(0.9, 0.1\big)\), 
    % Player 2's maximizes expected utility by playing \(s'_2 = \big(0, 1\big)\) (easy to check!).
    % \vspace{1em}

    % In other words, \(s'_2 = \big(0, 1\big)\) is Player 2's \emph{best response} to \(s_1 = \big(0.9, 0.1\big)\).
    % \vspace{1em}

    % So is \(\bm{s} = \big(s_1, s'_2\big)\) a Nash equilibrium?
    % \vspace{1em}

    % No! If Player 2 plays \(s'_2 = \big(0, 1\big)\), Player 1 
    % wants to deviate to \(s'_1 = \big( 0, 1\big)\):
    % \begin{flalign*}
    %     \qquad\EXP\Big[s_1 \mid s'_2 \Big] & = \EXP\Big[ \text{Heads} \mid s'_2\Big] \cdot 0.9 + \EXP\Big[ \text{Tails} \mid s'_2\Big] \cdot 0.1 &\\
    %         & = (-1) \cdot 0.9 + 1 \cdot 0.1 &\\ 
    %         & = -0.8& \\
    %     \qquad\EXP\Big[s'_1 \mid s'_2 \Big] & = \EXP\Big[ \text{Heads} \mid s'_2\Big] \cdot 0 + \EXP\Big[ \text{Tails} \mid s'_2\Big] \cdot 1 &\\
    %         & = (-1) \cdot 0 + 1 \cdot 1 &\\ 
    %         & = 1& \\
    %         & > \EXP\Big[s_1 \mid s'_2 \Big].&
    % \end{flalign*}    




    % Suppose Players 1 and 2 play mixed strategies 
    % \(s_1 = \big(p, 1-p\big)\) and \(s_2 = \big(q, 1-q\big)\), respectively, 
    % for \(p, q > 0\).
    % \vspace{1em}

    % Note that Player 2's expected payoff with these strategies is:
    % \begin{flalign*}
    %     \qquad\EXP\Big[s_2 \mid s_1\Big] & = \EXP\Big[\text{Heads} \mid s_1\Big] \cdot q + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot (1-q). &
    % \end{flalign*}
    % Suppose, now, that Player 1's strategy makes Heads more attractive for Player 2:
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1\Big] & > \EXP\Big[\text{Tails} \mid s_1\Big].&
    % \end{flalign*}
    % In this case, Player 2 would want to deviate to \(s'_2 = \big(1, 0\big)\):
    % \begin{flalign*}
    %     \qquad\EXP\Big[s'_2 \mid s_1\Big] & = \EXP\Big[\text{Heads} \mid s_1\Big] \cdot 1 + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot 0 &\\ 
    %     % & = \EXP\Big[\text{Heads} \mid s_1\Big] &\\ 
    %     & > \EXP\Big[\text{Heads} \mid s_1\Big] \cdot q + \EXP\Big[\text{Tails} \mid s_1\Big] \cdot (1-q).&
    % \end{flalign*}

    % So \(\bm{s} = \big(s_1, s_2\big)\) cannot be a Nash equilibrium.
    % Same if \(\EXP\Big[\text{Tails} \mid s_1\Big] > \EXP\Big[\text{Heads} \mid s_1\Big]\).
    % \vspace{1em}
    
    % The only way to avoid this is for Player 1 to play a strategy \(s^*_1 = (p, 1-p)\) that makes
    % Player 2 indifferent between their actions:
    % \begin{flalign*}
    %     \qquad\EXP\Big[\text{Heads} \mid s_1\Big] = \EXP\Big[\text{Tails} \mid s_1\Big] & 
    %         \text{ iff } (-1) \cdot p + 1 \cdot (1-p) = 1 \cdot p + (-1) \cdot (1-p)&\\ 
    %             & \text{ iff } p = \nicefrac{1}{2}.&
    % \end{flalign*}
    % So Player 1 wants to play \(s^*_1 = \big(\nicefrac{1}{2}, \nicefrac{1}{2}\big)\). 
    % Similarly, Player 2 wants to play \(s^*_2 = \big(\nicefrac{1}{2}, \nicefrac{1}{2}\big)\). This is the mixed Nash equilibrium.







    % A two-player game is \emph{zero-sum} if payoffs add up to zero in every outcome.
    % Specifically, if Player 1 plays action \(x\) and Player 2 plays action \(y\), then:
    % \[
    %     u_1(x, y) + u_2(x, y) = 0.
    % \]
    % \vspace{1em}
    % In other words, \(u_1(x, y) = - u_2(x, y)\).\\


    % \(\bm{s}^* = \Big( (\nicefrac{1}{2}, \nicefrac{1}{2}), (\nicefrac{1}{2}, \nicefrac{1}{2})\Big)\)

    % \(\bm{s}^* = \Big( \big(38.47\%, 61.53\% \big), (40.23\%, 59.77\%)\Big)\)

    % \(\bm{s}^* = \Big( (\nicefrac{3}{7}, \nicefrac{4}{7}), (\nicefrac{4}{7}, \nicefrac{3}{7})\Big)\)

    % \(\bm{s}^* = \big( \text{B}, \text{B}\big)\)

    % \(\bm{s}^* = \Big( (\nicefrac{1}{3}, \nicefrac{1}{3}, \nicefrac{1}{3}), (\nicefrac{1}{3}, \nicefrac{1}{3}, \nicefrac{1}{3})\Big)\)



    % \[
    %     \max \{-1, -1\} = -1.
    % \]

    % \[
    %     \min \{1, 1\} = 1.
    % \]



    % \[
    %     \max_{s_1}\min_{s_2} u_1{\big( s_1, s_2 \big)}.
    % \]

    % \[
    %     \min_{s_2} \max_{s_1} u_1{\big( s_1, s_2 \big)}.
    % \]



    % Players 1 and 2 play mixed strategies \(s_1 = \big(p, 1-p\big)\) and \(s_2 = \big(q, 1-q\big)\), respectively.
    % \vspace{1em}

    % And they want to maximize (minimize, respectively) the expected payoff:
    % \begin{flalign*}
    %     \qquad\EXP\Big[u_1{\big( s_1, s_2 \big)}\Big] 
    %         & = \EXP\Big[u_1{\big( \text{H}, s_2 \big)}\Big] \cdot p +                                                         
    %             \EXP\Big[u_1{\big( \text{T}, s_2 \big)}\Big] \cdot (1-p) \\
    %         &  = \Big(u_1{\big( \text{H}, \text{H} \big)} \cdot q + 
    %             u_1{\big( \text{H}, \text{T} \big)} \cdot (1-q) \Big) \cdot p + &\\
    %         & \qquad \Big(u_1{\big( \text{T}, \text{H} \big)} \cdot q + 
    %             u_1{\big( \text{T}, \text{T} \big)} \cdot (1-q)\Big) \cdot (1-p)\\
    %         &  = u_1{\big( \text{H}, \text{H} \big)} \cdot p \cdot q + 
    %             u_1{\big( \text{H}, \text{T} \big)} \cdot p \cdot (1-q) + &\\
    %         & \qquad u_1{\big( \text{T}, \text{H} \big)} \cdot (1-p) \cdot q + 
    %             u_1{\big( \text{T}, \text{T} \big)} \cdot (1-p) \cdot (1-q)&\\
    %         & = 4pq - 2p - 2q + 1.
    % \end{flalign*}



    % Think of the expected utility as a function of \(p\) and \(q\):
    % \[
    %     f(p, q) = 4pq - 2p - 2q + 1.
    % \]
    % We want to find \(\max_{p}\min_q f(p, q)\).
    % \vspace{1em}

    % Player 2 wants to minimize \(f(p, q)\) by choosing \(q\).
    % To find the value for \(q\), take the partial derivative of \(f\) with respect to \(q\):
    % \begin{flalign*}
    %     \qquad\frac{\partial f}{\partial q} & = 4p - 2.&
    % \end{flalign*}
    % The sign of the partial derivative tells us whether \(f\) is increasing or decreasing with respect to \(q\).
    % If \(4p - 2 < 0\), \(f\) is decreasing and Player 2 sets \(q = 1\). 
    % If \(4p - 2 > 0\), \(f\) is increasing and Player 2 sets \(q = 0\). 
    % If \(4p - 2 = 0\), \(f\) is constant at \(f(p, \nicefrac{1}{2}) = 0\).
    % \vspace{1em}
    




    % So Player 1's worst-case payoff is:\
    % \begin{flalign*}
    %     \qquad\min_q f(p, q) & = 
    %         \begin{cases}
    %             2p-1, & \text{if }  0 \leq p < \nicefrac{1}{2},\\
    %             0, & \text{if } p = \nicefrac{1}{2},\\
    %             -2p +1, & \text{if } \nicefrac{1}{2} < p \leq 1.
    %         \end{cases} &
    % \end{flalign*}
    % Player 1 wants to maximize this worst-case payoff, 
    % which in this case happens at \(p^* = \nicefrac{1}{2}\).



    % The symmetric calculation shows that Player 2's strategy that minimizes Player 1's best-case expected payoff is: 
    % \[
    %     q^* = \nicefrac{1}{2}.
    % \]
    % Note that in this case:
    % \[
    %     \max_p \min_q f(p, q) = \min_q \max_p f(p, q) = 0.
    % \]

    % \[
    %     \max_{s_1} \min_{s_2} \EXP\Big[u_1{\big( s_1, s_2 \big)}\Big] = 
    %     \min_{s_2} \max_{s_1} \EXP\Big[u_1{\big( s_1, s_2 \big)}\Big].
    % \]




    % The Kicker and Goalkeeper play mixed strategies \(s_{\text{K}} = \big(p, 1-p\big)\)
    % and \(s_{\text{G}} = \big(q, 1-q\big)\), respectively.
    % \vspace{1em}

    % To get the mixed Nash equilibrium, we find the values of \(p\) and \(q\) that
    % make the Kicker and the Goalkeeper indifferent between their actions:
    % \begin{flalign*}
    %     % \quad
    %     \EXP\Big[u_{\text{K}}\big(\text{L}, s_{\text{G}}\big)\Big] = \EXP\Big[u_{\text{K}}\big(\text{R}, s_{\text{G}}\big)\Big] & 
    %         \text{ iff } 0 \cdot q + 1 \cdot (1-q) = \frac{3}{4} \cdot q + 0 \cdot (1-q)&\\ 
    %             & \text{ iff } q = \frac{4}{7}.& \\
    %     \EXP\Big[u_{\text{G}}\big(s_{\text{K}}, \text{L}\big)\Big] = \EXP\Big[u_{\text{G}}\big(s_{\text{K}}, \text{R}\big)\Big] & 
    %         \text{ iff } 1 \cdot p + \frac{1}{4} \cdot (1-p) = 0 \cdot p + 1 \cdot (1-p)&\\ 
    %             & \text{ iff } p = \frac{3}{7}.&
    % \end{flalign*}
    % Interestingly, the Kicker now shoots to their weak side (right) more often!
    % \vspace{1em}

    % What's going on here?




    % Write \(x\), \(y\), \(z\), \(t\), for the various average success rates of the Kicker 
    % (see payoffs on the right).
    % \vspace{1em}

    % Statistics give us the average numbers displayed (as percentages).
    % \vspace{1em}

    % This gives us a very specific prediction, as the mixed Nash equilibrium.





    % \(u_i(s_1, s_2) = \sum_t u_i^t(s_1, s_2)\)

    % \[
    %     u_i(s_1, s_2) = \sum_t u_i^t(s_1, s_2) \cdot \delta^{t-1}
    % \]
    

    % Assume there is a probability \(\delta\), called the \emph{discount factor}, 
    % that the game is played again at round \(t+1\),
    % given that it was played at round \(t \geq 1\).
    % \vspace{1em}

    % Payoffs are calculated as expected values, depending on \(\delta\).



    % The deviation is not worth it just in case:
    % \begin{flalign*}
    %     \qquad
    %     2 + 2\delta + 2\delta^2 + \dots + 2\delta^{k-1} + 2\delta^k + \dots & \geq 2 + 2\delta + 2\delta^2 + \dots + 2\delta^{k-1} + 3\delta^k & \text{iff}\\
    %     2\delta^k + 2\delta^{k+1} + \dots & \geq 3\delta^k & \text{iff}\\
    %     2\delta + 2\delta^2 + \dots & \geq 1 & \text{iff} \\ 
    %     2\delta (1 + \delta + \dots) & \geq 1 & \text{iff} \\ 
    %     2 \delta \cdot \frac{1}{1-\delta} & \geq 1 & \text{iff} \\ 
    %     \delta & \geq \frac{1}{3}. &
    % \end{flalign*}




    % We assume a population with a fraction of \(p\) cooperators and \(1-p\) defectors.
    % \vspace{1em}

    % Fix an arbitrary agent \(i\) in the population, called the \emph{focal agent}.
    % \vspace{1em}

    % Pick another agent \(j\) from the population as \(i\)'s pair.
    % \vspace{1em}

    % If \(j\) is selected uniformly at random, the probabilities of \(j\) being a cooperator or a defector are, roughly:\(^*\)
    % \begin{flalign*}
    %     \quad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{C} \big]}  &= p, & 
    %     \quad
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{C} \big]}  &= 1 - p,&\\
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{D} \big]}  &= 1 - p, &
    %     \quad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{D} \big]}  &= p.&
    % \end{flalign*}


    When paired, we assume the focal agent \(i\) is player \(1\), and agent \(j\) is player \(2\).
    \vspace{1em}

    And we look only at the payoffs of the focal agent.
    \vspace{1em}

    Thus:
    \begin{flalign*}
        \qquad
        & u(C, D) &
    \end{flalign*}
    is the payoff of player \(i\) when \(i\) is a cooperator and \(j\) is a defector.



    % There are \(p\) cooperators and \(1-p\) defectors.
    % The focal agent \(i\) is paired with another agent \(j\).
    % \vspace{1em}

    % With uniformly random pairing, the probabilities are:
    % \begin{flalign*}
    %     \qquad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{C} \big]}  &= p, & 
    %     \qquad
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{C} \big]}  &= 1 - p,&\\
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{D} \big]}  &= 1-p, &
    %     \qquad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{D} \big]}  &= p.&
    % \end{flalign*}


    % The expected payoffs if \(i\) is a cooperator (C) or a defector (D) are:
    % \begin{flalign*}
    %     \qquad
    %     \EXP\big[\text{C}\big] & = u\big(\text{C}, \text{C}\big) \cdot {\Pr}{\big[ j=\text{C} \mid i=\text{C} \big]} +
    %                                 u\big(\text{C}, \text{D}\big) \cdot  {\Pr}{\big[ j=\text{D} \mid i = \text{C} \big]}& \\ 
    %                                    & = 2 \cdot p + (-1) \cdot (1-p)& \\
    %                                    & = 3p - 1.&\\
    %     \EXP\big[\text{D}\big] & = u\big(\text{D}, \text{C}\big) \cdot {\Pr}{\big[ j = \text{C} \mid i = \text{D} \big]} +
    %                                 u\big(\text{D}, \text{D}\big) \cdot {\Pr}{\big[ j = \text{D} \mid i = \text{D} \big]}& \\ 
    %                                 & = 3 \cdot p + 0 \cdot (1-p)&\\
    %                                 & = 3p &\\
    %                                 & > \EXP[\text{C}].&
    % \end{flalign*}



    % There are \(p\) cooperators and \(1-p\) defectors.
    % The focal agent \(i\) is paired with another agent \(j\).
    % \vspace{1em}

    % Write general terms for the pairing probabilties:
    % \begin{flalign*}
    %     \qquad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{C} \big]}  = q_{\text{C}}, & 
    %     \qquad
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{C} \big]}  = 1 - q_{\text{C}},&\\
    %     {\Pr}{\big[ j = \text{D} \mid i = \text{D} \big]}  = q_{\text{D}}, &
    %     \qquad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{D} \big]}  = 1-q_{\text{D}}.&
    % \end{flalign*}

    % The expected payoffs are:
    % \begin{flalign*}
    %     \qquad
    %     \EXP\big[\text{C}\big] & = u\big(\text{C}, \text{C}\big) \cdot {\Pr}{\big[j=\text{C} \mid i=\text{C}\big]} + 
    %                                u\big(\text{C}, \text{D}\big) \cdot  {\Pr}{\big[j=\text{D}\mid i=\text{C}\big]}& \\ 
    %                                & = (b-c) \cdot q_{\text{C}} + (-c) \cdot (1-q_{\text{C}})& \\
    %                                & = b \cdot q_{\text{C}} - c&\\
    %     \EXP\big[\text{D}\big] & = u\big(\text{D}, \text{C}\big) \cdot {\Pr}{\big[j=\text{C} \mid i=\text{D}\big]} +
    %                                 u\big(\text{D}, \text{D}\big) \cdot  {\Pr}{\big[j=\text{D}\mid i=\text{D}\big]}& \\ 
    %                                & = b \cdot (1-q_{\text{D}}) + 0 \cdot q_{\text{D}} &\\ 
    %                                & = b - b \cdot q_{\text{D}}.&                                
    % \end{flalign*}
    % Cooperation survives if:
    % \begin{flalign*}
    %     \qquad
    %     \EXP\big[\text{C}\big] > \EXP\big[\text{D}\big] & \text{ iff } b \cdot q_{\text{C}} - c > b - b \cdot q_{\text{D}}& \\
    %                                                     & \text{ iff } q_{\text{C}} - (1 - q_{\text{D}}) > \frac{c}{b}.&
    % \end{flalign*}





    % Cooperation increases in frequency if and only if:
    % \begin{flalign*}
    %     \qquad
    %     {\Pr}{\big[ j = \text{C} \mid i = \text{C} \big]} - {\Pr}{\big[ j = \text{C} \mid i = \text{D} \big]} &> \frac{c}{b}.&
    % \end{flalign*}



    % Assume that at some time \(t\) there are \(c\) cooperators and \(d\) defectors.\\

    % The expected payoff of a cooperator is:
    % \begin{flalign*}
    % \quad\EXP\big[\text{Cooperate}\big] & = u\big(\text{Cooperate}, \text{Cooperate}\big) \cdot {\Pr}{\left[ \text{match w/ cooperator} \right]} + &\\
    %                                    &~~~~~u\big(\text{Cooperate}, \text{Defect}\big) \cdot  {\Pr}{\left[ \text{match w/ defector} \right]}&\\ 
    %                                    & = 2 \cdot \frac{c-1}{c+d} + 0 \cdot \frac{d}{c+d}.&
    % \end{flalign*}

    % The expected payoff of a defector is:
    % \begin{flalign*}
    %     \quad\EXP\big[\text{Defect}\big] & = u\big(\text{Defect}, \text{Cooperate}\big) \cdot {\Pr}{\left[ \text{match w/ cooperator} \right]} +& \\
    %                                      & ~~~~~u\big(\text{Defect}, \text{Defect}\big) \cdot {\Pr}{\left[ \text{match w/ defector} \right]}&\\ 
    %                            & = 3 \cdot \frac{c}{c+d} + 1 \cdot \frac{d-1}{c+d}.
    % \end{flalign*}
    % Note that \(\EXP[\text{Defect}] > \EXP[\text{Cooperate}]\).\\

    % Defectors grow faster than cooperators.\\ 

    % Eventually, cooperators die out.

    % Assume the proportions of Bs is \(\epsilon \), and the proportion of As is \(1-\epsilon \).\\

    % The expected payoff of A is greater than that of B if:
    % \[
    %     a(1- \epsilon ) + b \epsilon > c(1-\epsilon ) + d \epsilon,
    % \]
    % which, if we ignore the \(\epsilon \) terms, is equivalent to:
    % \[
    %     a > c.
    % \]
    % If, however, it happens that \(a=c\), then we need:
    % \[
    %     b > d.
    % \]
    % A strategy is evolutionarily stable if \(a>c\), or \(a=c\) and \(b>d\).

    % We write \(u(s_i, s_j)\) for the payoff of strategy \(s_i\) against \(s_j\).\\

    % Strategy \(s_i\) is an \emph{evolutionarily stable strategy (ESS)} if:
    % \begin{description}
    %     \item[(i)] \(u(s_i, s_i) > u(s_j, s_i)\), for all strategies \(s_j \neq s_i\), or
    %     \item[(ii)] \(u(s_i, s_i) = u(s_j, s_i)\) and \(u(s_i, s_j) > u(s_j, s_j)\), for all strategies \(s_j \neq s_i\).
    % \end{description}

    % \(b-c, b-c\)
    % \((b-c)\mu, (b-c)\mu\)
    % \(b, -c\)
    % \(-c, b\)
    % \(0, 0\)

    % TFT is an ESS if the occasional ALLD, thrown in a world where TFT is dominant,
    % does worse against a TFT than a TFT against itself.\\

    % This happens if:
    % \begin{flalign*}
    %     b < (b-c)\mu &\text{  iff  } \mu> \frac{b}{b-c} &\\
    %                  & \text{  iff  } \frac{1}{1-\delta } > \frac{b}{b-c} &\\
    %                  & \text{  iff  } \frac{1}{1-\delta } > \frac{b}{b-c} &\\
    %                  & \text{  iff  } b-c > b(1-\delta ) &\\
    %                  & \text{  iff  } \delta  > \frac{c}{b}. &
    % \end{flalign*}

    % ALLD is an ESS if a population of ALLDs cannot be invaded by TFTs.\\

    % This happens if a TFT against an ALLD does worse than an ALLD against
    % another ALLD, which is equivalent to:
    % \[
    %     -c < 0.
    % \]

    % \(\mu = \frac{1}{1-\delta}\)

    % \(b + b \cdot w + b \cdot w^2 + 0 \cdot w^3\)
    % \(-c + 0 \cdot w + 0 \cdot w^2 + 0 \cdot w^3\)
    % \((b-c) + (-c) \cdot w + 0 \cdot w^2 + 0 \cdot w^3\)
    % \((b-c) + (b-c) \cdot w + (-c) \cdot w^2 + 0 \cdot w^3\)

    % \(b \cdot (1+w+w^2)\)
    % \(-c\)
    % \(b - c \cdot (1+w)\)
    % \(b \cdot (1+w) - c \cdot (1+w+w^2)\)

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(b\) & \(-c\) & \(b-c\) &\(b-c\)\\
    %     \(t=2\) & \(b \cdot  w\) & \(0\cdot w\) & \((-c)\cdot w \) &\((b-c)\cdot w \)\\
    %     \(t=3\) & \(b \cdot w^2\) & \(0\cdot w^2 \) & \(0\cdot w^2 \) &\((-c)\cdot w^2\)\\
    %     \(t=4\) & \(0 \cdot w^3\) & \(0\cdot w^3 \) & \(0\cdot w^3 \) &\(0 \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   & \(b\cdot \epsilon_2\) 
    %             & \(-c\) 
    %             & \(b - c \cdot \epsilon_1\)
    %             & \(b \cdot \epsilon _1 - c \cdot \epsilon _2\)\\
    %     \bottomrule
    % \end{tabular}

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(b\) & \(b\) & \(b\) &\(b\)\\
    %     \(t=2\) & \(b \cdot  w\) & \(b\cdot w\) & \(b\cdot w \) &\(b\cdot w \)\\
    %     \(t=3\) & \(b \cdot w^2\) & \(b\cdot w^2 \) & \(b\cdot w^2 \) &\(b\cdot w^2\)\\
    %     \(t=4\) & \(b \cdot w^3\) & \(b\cdot w^3 \) & \(b\cdot w^3 \) &\(b \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     & \(b\cdot \overline{\epsilon}\)
    %     \\
    %     \bottomrule
    % \end{tabular}

    % \begin{tabular}{cllll}
    %     \toprule
    %     & \(1\) & \(2\) & \(3\) & \(4\) \\ 
    %     \midrule
    %     \(t=1\) & \(0\) & \(0\) & \(0\) &\(0\)\\
    %     \(t=2\) & \(0 \cdot  w\) & \(0\cdot w\) & \(0\cdot w \) &\(0\cdot w \)\\
    %     \(t=3\) & \(0 \cdot w^2\) & \(0\cdot w^2 \) & \(0\cdot w^2 \) &\(0\cdot w^2\)\\
    %     \(t=4\) & \(0 \cdot w^3\) & \(0\cdot w^3 \) & \(0\cdot w^3 \) &\(0 \cdot w^3\)\\
    %     \dots   &\\
    %     \midrule
    %     total   
    %     & \(0\)
    %     & \(0\)
    %     & \(0\)
    %     & \(0\)
    %     \\
    %     \bottomrule
    % \end{tabular}

    % Keeping in mind that, for \(0 < w < 1\), it holds that:
    % \begin{flalign*}
    %     \qquad\epsilon _n & = 1 + w + w^2 + \dots + w^n &\\
    %                 & = \frac{1-w^{n+1}}{1-w}, &
    % \end{flalign*}
    % with the infinite sum, i.e., for \(n \rightarrow \infty\), being:
    % \begin{flalign*}
    %     \qquad\overline{\epsilon} & = 1 + w + w^2 + \dots &\\
    %                 & = \lim_{n\rightarrow\infty}(1 + w + w^2 + \dots + w^n)&\\
    %                 & = \frac{1}{1-w}.&
    % \end{flalign*}



    % Note that if there is just one ALLD we get a chain of defections, 
    % and eventually all the UTFTs end up defecting permanently.\\

    % The number of rounds until a UTFT starts defecting depends on 
    % the number of consecutive UTFTs upstream:
    % \begin{itemize}
    %     \item at round \(t=2\), player \(1\) starts defecting

    %     \dots

    %     \item at round \(t = i+1\), player \(i\) starts defecting.
    % \end{itemize}
    % So the number of consecutive UTFTs upstream also determines 
    % a player's payoff.


    % An ALLD with \(u\) UTFTs upstream gets a payoff of \(b\) for \(u\) rounds 
    % (i.e., until the immediately upstream UTFT is converted to defection), 
    % and \(0\) afterwards, so its expected payoff is:
    % \begin{flalign*}
    %     \quad v(\text{ALLD}\mid u) & = b + b \cdot w + \dots + b \cdot w^{u-1} &\\
    %                          & = b \cdot(1 + w + \dots + w^{u-1}) \\ 
    %                          & = b \cdot \epsilon_{u-1}.
    % \end{flalign*}
    % A UTFT with \(u\) UTFTs upstream gets a payoff of \(b-c\) for the first \(u\) rounds 
    % (i.e., while the directly upstream player cooperates), \(-c\) at round \(u+1\)
    % (i.e., when it gets defected on), and \(0\) afterwards (after it starts defecting itself).\\

    % So, if \(u < n-1\), the expected payoff is:
    % \begin{flalign*}
    %     \quad v(\text{UTFT}\mid u) & = (b-c) + (b-c) \cdot w + \dots + (b-c) \cdot w^{u-1} + (-c) \cdot w^u &\\
    %                          & = b \cdot(1 + w + \dots + w^{u-1}) - c \cdot (1 + w + \dots + w^u)\\ 
    %                          & = b \cdot \epsilon_{u-1} - c \cdot \epsilon _u,
    % \end{flalign*}
    
    % Unless, of course, everyone is a UTFT (\(u = n-1\)), in which case payoffs are \(b-c\) forever:
    % \begin{flalign*}
    %     \quad v(\text{UTFT}\mid u) & = (b-c) + (b-c) \cdot w + (b-c) \cdot w^2 + \dots &\\
    %                          & = (b-c) \cdot(1 + w + w^2 + \dots)\\ 
    %                          & = (b-c) \cdot \overline{\epsilon },
    % \end{flalign*}
    % if \(u = n-1\).

    % Take \(p\) to be the frequency of UTFTs at round \(t\):
    % \[
    %     p = \frac{\text{\# of UTFTs at }t}{n}.
    % \]
    % The frequency of ALLDs at \(t\) is then \(1-p\).\\

    % Write \(W_\UTFT\) and \(W_\ALLD\) for the fitness of UTFT and ALLD at round \(t\).\\

    % The fitness \(W_s\) of strategy \(s\) (a function of expected payoff, computed earlier) can be interpreted 
    % as the probability that an individual using \(s\) reproduces.\\

    % So the (expected) number of UTFTs that get to reproduce at \(t\) is \(p \cdot n \cdot W_\UTFT\).\\

    % Similarly, the (expected) number of ALLDs that get reproduce at \(t\) is \((1-p) \cdot n \cdot W_\ALLD\).\\

    % Let's say that each reproducing individual has \(z\) offspring, i.e., copies of itself.\\

    % So at \(t+1\) we get \(p \cdot n \cdot W_\UTFT \cdot z\) UTFTs.\\

    % And the proportion of UTFTs at \(t+1\) is:
    % \begin{flalign*}
    %     p' & = \frac{\text{\# of UTFTs at }t+1}{\text{total \# of players at }t+1} \\
    %        & = \frac{p \cdot n \cdot W_\UTFT \cdot z}{p \cdot n \cdot W_\UTFT \cdot z + (1-p) \cdot n \cdot W_\ALLD \cdot z}\\
    %        & = \frac{p \cdot W_\UTFT}{p \cdot W_\UTFT + (1-p) \cdot W_\ALLD}.
    % \end{flalign*}

    % Assume \(\nicefrac{b}{c} = 2\).\\

    % If the initial fraction of UTFTs is above the threshold frequency,
    % the system evolves to a world with all UTFTs.\\

    % Below this threshold we get ALLDs.\\ 

    % Note that as populations grow larger, the threshold frequency becomes forbiddingly high.






    % Assume \(\nicefrac{b}{c} = 2\).\\

    % If the initial fraction of UTFTs is above the threshold frequency of \(r\),
    % UTFTs can increase when rare.\\

    % Again, for larger populations, the threshold frequency becomes forbiddingly high.
\end{document}