%% magick convert -density 1200 test.pdf test.png
\documentclass[preview, border={0pt 2pt 1pt 1pt}, varwidth=9cm]{standalone} % border options are {left bottom right top}

\input{input/packages.tex}
\input{input/colors.tex}
\input{input/macros.tex}

\begin{document}
    \raggedright
    % \[
    %     {\Pr}\Big[H \mid E \Big] = \frac{{\Pr}\big[ E \mid H\big] \cdot {\Pr}\big[H\big]}{{\Pr}\big[E\big]}.
    % \]



    % Nature decides whether a disease occurs (\(d\)) with \emph{prior probability}, 
    % or \emph{base rate}, \(b\):
    % \[
    %     {\Pr}\big[d\big] = b, \qquad \Pr[\lnot d] = 1-b.
    % \]
    % A test is administered, which returns either a \emph{positive result} (+),
    % or a \emph{negative result} (-).
    % \newline
    
    % A \emph{false positive} occurs with probability \(\alpha\):
    % \[
    %     \Pr[+ \mid \lnot d] = \alpha, \qquad \Pr[- \mid \lnot d] = 1 - \alpha.
    % \]
    % A \emph{false negative} occcurs with probability \(\beta\):
    % \[
    %     \Pr[- \mid d] = \beta, \qquad \Pr[+ \mid d] = 1 - \beta.
    % \]



    % For the MaterniT21 test, the base rate of the disease is one in \(2{,}500\) pregnancies,
    % i.e., \(\Pr[d] = 0.0004\).
    % \newline

    % When the disease is present, the test identifies it with probability \(0.99\)
    % (the test makers were not lying about this), 
    % so the false negative rate is \(\Pr[- \mid d] = 0.01\).
    % \newline

    % The false positive rate is \(\Pr[+ \mid \lnot d] = 0.00022\). Quite low!
    % \newline

    % Now suppose you're one of the women who just got a positive result.
    % \newline

    % Is this because of a genetic disease, or a false positive?
    % \newline

    % What you really want to find out is the probability of the disease 
    % \emph{given} a positive test: 
    % \[
    %     \Pr[d \mid +]=\,\, ?.
    % \]
    % How do we get this?



    % We know that \(\Pr[d] = 0.0004\), \(\Pr[- \mid d] = 0.01\) and \(\Pr[+ \mid \lnot d] = 0.00022\).
    % \newline

    % By Bayes' rule, we have:
    % \begin{flalign*}
    %     \qquad \Pr[d \mid +] & = \frac{\Pr[+ \mid d] \cdot \Pr[d]}{\Pr[+]}& \\ 
    %                          & = \frac{\Pr[+ \mid d] \cdot \Pr[d]}{\Pr[+ \mid d]\cdot \Pr[d] + \Pr[+ \mid \lnot d] \cdot \Pr[\lnot d]}\\ 
    %                          & = \frac{0.99 \cdot 0.0004}{0.99 \cdot 0.0004 + 0.00022 \cdot 0.9996}\\ 
    %                          & = 0.643.
    % \end{flalign*}
    % So about a third of the positive results is a dud.



    % Suppose we know the base rate, false positive rate and false positive rate.
    % \newline

    % Testing once, we get a signal \(s_1 \in \{+, -\}\).
    % Updating, we obtain the posterior \(\Pr\left[ d \mid s_1 \right]\).
    % \newline

    % Testing again, we obtain a new (independent) signal \(s_2 \in \{+, -\}\).
    % \newline

    % We update again, with \(\Pr\left[ d \mid s_1 \right]\) as the new prior:
    % \begin{flalign*}
    %     \qquad \Pr[d \mid s_2, s_1] & = \frac{\Pr\left[ d, s_2, s_1 \right]}{\Pr\left[s_2, s_1 \right]}& \\ 
    %                            & = \frac{\Pr\left[ s_2 \mid d, s_1 \right] \cdot \Pr\left[ d, s_1 \right]}{\Pr\left[ s_1, s_2 \right]}\\ 
    %                            & = \frac{\big(\Pr\left[ s_2 \mid d \right] \cdot \Pr\left[ s_1 \mid d \right]\big) \cdot \Pr\left[ d \right]}{\Pr\left[ s_1, s_2 \right]}
    % \end{flalign*}






    % Consider a disease that can affect foetuses.

    % \vspace{0.2cm}
    % The base rate of the disease
    % is \({\Pr}\big[ d \big] = 0.1\), i.e., out of \(100\) foetuses \(10\) will be afflicted.
    % \newline

    % A diagnostic test detects the disease with probability \({\Pr}\big[ + \mid d \big] = 0.9\),
    % i.e., it catches \(9\) out of the \(10\) cases.
    % \newline

    % The false positive rate is \({\Pr}\big[ + \mid \lnot d \big] = 0.1\),
    % i.e., \(9\) out of the \(90\) healthy foetuses 
    % show up incorrectly as positive results.
    % \newline
    
    % Bayes rule tell us:
    % \begin{flalign*}
    %     \qquad {\Pr}\Big[d \mid +\Big] & = \frac{{\Pr}\big[+ \mid d\big] \cdot {\Pr}\big[d\big]}{{\Pr}\big[+\big]}& \\ 
    %                          & = \frac{{\Pr}\big[+ \mid d\big] \cdot {\Pr}\big[d\big]}{{\Pr}\big[+ \mid d\big]\cdot {\Pr}\big[d\big] + {\Pr}\big[+ \mid \lnot d\big] \cdot {\Pr}\big[\lnot d\big]}\\ 
    %                          & = \frac{0.9 \cdot 0.1}{0.9 \cdot 0.1 + 0.1 \cdot 0.9}\\ 
    %                          & = 0.5.
    % \end{flalign*}
    % Half of the positive results are healthy foetuses!



    Note that if the disease is rarer, say \({\Pr}\big[ d \big] = 0.05\),
    then the same test parameters give us:
    \[
        {\Pr}\big[ d \mid + \big] \approx 0.32.
    \]
    With a positive result you're actually twice as likely to be healthy!

    


    % For the MaterniT21 case, one positive result gave us:
    % \[
    %     \Pr\left[ d \mid + \right] = 0.64.
    % \]
    % Two positive test results and we can be virtually certain:
    % \[
    %     \Pr\left[ d \mid +, + \right] = 0.9998.
    % \]
    % Three positive results and we can be even certainer:
    % \[
    %     \Pr\left[ d \mid +, +, + \right] = 0.9999.
    % \]


    % The experimenter chooses a hypothesis \(h\) to test.
    % Experiments yield positive (+) or negative results (-).
    % Confidence in \(h\) gets updated.
    % \newline

    % Recall that the base rate \(b\) matters for the quality of the 
    % results, so the experimenter should choose wisely
    % what to test: very unlikely hypotheses are going to be 
    % difficult to figure out.
    % \newline

    % A game against Nature?...

    % hypothesis \(h'\)


    % \(
    %     \underbrace{{\Pr}\big[\text{Data} \mid \text{Null Hypothesis}\big]}_{\text{p-value}} \neq \underbrace{{\Pr}\big[ \text{Null Hypothesis} \mid \text{Data} \big]}_{\text{what we usually want to know}}    
    % \)


    % Scientific publishers, especially high impact journals, 
    % often exhibit a bias in favor of positive results.
    % \newline

    % Assume a positive result (+) is always published.
    % \newline

    % A negative result (-) is published with probability \(1-\rho\).
    % \newline

    % The \emph{publication bias} \(\rho\) is thus the probability 
    % that a negative result fails to be published.
    % \newline 

    % There is a \emph{threshold \(\tau\) for canonization}, 
    % i.e., the posterior \({\Pr}{\left[ h \mid\text{Evidence} \right]}\) 
    % has to be higher than \(\tau\) for the result to be accepted.




    
    % There is a population \(N = \{1, \dots, n\}\) of \emph{scientific labs}.
    % \newline

    % Lab \(i\) tests a hypothesis \(h\).
    % Its \emph{power} is the true positive rate \(W_i = \Pr\left[ + \mid h \right]\).
    % The \emph{false positive} rate is \(\alpha_i = \Pr\left[ + \mid \lnot h \right]\).
    % \newline

    % Lab \(i\) has an \emph{effort level} \(i\) that, together with \(W_i\),
    % determines the false positive rate:
    % \[
    %     \alpha_i = \frac{W_i}{1+ (1-W_i)e_i}.
    % \]
    % The idea, (counter)intuitively, is that the false positive rate grows with power,$^{*}$
    % but the effect is dampened by higher effort.

    % \begin{flushright}
    %     \footnotesize
    %     $^*$ You can get a true positive rate of \(1\) by saying yes to everything!
    % \end{flushright}




    % Lab \(i\) investigates a new hypothesis \(h\) with a probability 
    % that depends on effort:
    % \[
    %     \Pr\left[ \text{new study} \right] = 1 - \eta \log e_i
    % \]
    % The higher the effort, the lower the chance to take on new work.
    % \newline

    % Positive results are always published, negative results are published 
    % with probability \(1-\rho\).
    % \newline

    % Positive results yield payoff of \(1\), negative results yield payoff \(v \leq 1\).



    % Ten labs are chosen at random, and the oldest dies.
    % \newline

    % Another ten labs are randomly chosen, and the one with the highest 
    % fitness reproduces: an offspring lab is created with the parameters
    % of the parent lab.
    % \newline

    % There are also mutation probabilities \(\mu_W\) and \(\mu_e\).




    % Keeping effort constant (\(e = 75, \mu_e = 0\)),
    % power evolves to its maximum value and the 
    % false discovery rate grows.



    % Keeping power constant (\(W = 0.8, \mu_W = 0\))
    % and allowing effort to evolve, we see effort 
    % going to its minimum value and the false discovery rate growing again.
\end{document}